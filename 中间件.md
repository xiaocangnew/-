### 优缺点：
- redis
  - 优点：
     性能好，并发高
  - 缺点：
     1. 缓存和数据库双写一致性问题
          一致性问题是分布式常见问题，还可以再分为最终一致性和强一致性。数据库和缓存双写，就必然会存在不一致的问题。
          redis只能保证最终一致性, 降低不一致发生的概率，无法完全避免。如果对数据有强一致性要求，不能放缓存。
     2. 缓存雪崩问题
     3. 缓存击穿问题
     4. 缓存的并发竞争问题
     
- 消息队列
   - 优点：
      解耦、异步、削峰，水平扩展
   - 中间件缺点有：
      1.系统可用性降低，依赖mq组件的高可用
      2.系统复杂度提高，消息不被重复消费,保证消息可靠性传输不丢失,消息顺序性
      3.数据一致性问题
   - kafka的缺点(中间件本身有可用性降低和复杂性升高的问题)
      1. 由于是批量发送，数据并非真正的实时；
      2. 仅支持统一分区内消息有序，无法实现全局消息有序；
      3. 监控不完善，需要安装插件；
      4. 依赖zookeeper进行元数据管理；
      5*. 对于mqtt协议不支持；
      6*. 不支持物联网传感数据直接接入；
   - rabbitmq的缺点
      1. 使用erlang开发，社区活跃度
      
- rpc的优缺点
    - 优点
      1. 性能消耗低，传输效率高，服务治理方便
    - 缺点
      1. 
      
### 如何保持数据可靠性 (不丢消息)
- rabbitmq
   1. producer引入事务机制或者Confirm机制
   2. 消息队列进行消息持久化， 同时引入mirrored-queue镜像队列
       1.exchange持久化：channel.exchangeDeclare(exchangeName,"direct/topic/header/fanout",true);
       2.queue持久化：channel.queueDeclare(queueName,true,false,false,null);
       3.message持久化发送,设置BasicProperties的deliverayMode=2：
   3. consumer不自动ack，处理完成后再ack，
   4. 消息补偿机制，发送消息前入库，缺失消息后可以重发；  
- kafka
   1. broker级别：关闭不完全的Leader选举
         unclean.leader.election.enable=false；不允许非ISR中的副本被选举为leader，以避免数据丢失
   2. topic级别：
         replication.factor>=3，并且 min.insync.replicas>=2；
   3. producer级别：
       1.acks=all（或者 request.required.acks=-1），
       2.发送模式为同步 producer.type=sync (异步时发送后先保存在缓冲区中，如果宕机则丢失全部消息)
       3.关闭自动提交：enable.auto.commit=false
       4.提交缓冲区满后一直阻塞不抛异常：block.on.buffer.full = true  尽管该参数在0.9.0.0已经被标记为“deprecated”，
         但鉴于它的含义非常直观，所以这里还是显式设置它为true，使得producer将一直等待缓冲区直至其变为可用。
         否则如果producer生产速度过快耗尽了缓冲区，producer将抛出异常。缓冲区满了就阻塞在那，不要抛异常，也不要丢失数据       
  
### 数据持久性
- 关键的问题是消息在正确存入mq之后，还需要有一段时间（这个时间很短，但不可忽视）才能存入磁盘之中，
   mq并不是为每条消息都做fsync的处理，可能仅仅保存到cache中而不是物理磁盘上
   1. rabbitmq 引入镜像队列来延缓这一问题；
   2. kafka通过多副本机制来延缓这一问题；
   
### 如何保持幂等
- rabbitmq
   1. 生产者幂等
        producer本身没有这种机制，有可能重复发送
   2. 消费者幂等
        consumer没有这种机制， 只能是业务代码中自己实现，使用3方法
   3. 定制消息(唯一ID+指纹码机制)
      整个思路就是首先我们需要根据消息生成一个全局唯一的ID，然后还需要加上一个指纹码。
      将ID + 指纹码 拼接好的值作为数据库唯一键，就可以进行去重了。
      在消费消息前，先去数据库查询这条消息的指纹码标识是否存在，没有就执行insert操作，如果有就代表已经被消费了，就不需要管了。
      高并发下有数据库写入的性能瓶颈解决方案：跟进ID进行分库分表进行算法路由
- kafka
   1. 生产者单独幂等
       1. 单个分区只会发送一次，不会出现重复消息
            为了实现Producer的幂等性，Kafka引入了Producer ID（即PID）和Sequence Number。
            Broker端在缓存中保存了这seq number，对于接收的每条消息，如果其序号比Broker缓存中序号大于1则接受它，否则将其丢弃。这样就可以实现了消息重复提交了。
            但是只能保证单个Producer对于同一个<Topic, Partition>的Exactly Once语义。不能保证同一个Producer一个topic不同的partion幂等。
       2. 多个分区的原子性写入，即写入到多个分区的消息要么全部成功，要么全部回滚
            事务
   2. 消费者单独幂等
        没有这种机制，需要业务代码自己实现，类似rabbitmq
   2. 生产者+消费者幂等
       1. 事务(本质上可看成是“读取-处理-写入的管道”。保证整个过程的操作是原子性)
  
### 消息顺序性
- rabbitmq
   1. producer保证发送消息的顺序性：
       1. channel内发送的消息是保证顺序性的， 自研确保channel与线程绑定。
       2. 继承AbstractRoutingConnectionFactory， 实现lookupkey方法，每个factory中只用一个channel。
   2. consumer端保证接受消息的顺序性
       1. 一个queue只用一个consumer消费(防止多消费者时，一个consumer消费失败，又传给别人消费)
    
- kafka (只能保证在同一个partition内有序，在多个partition内无法保证有序)
  方法1
      设置max.in.flight.requests.per.connection=1.
       默认值是5，意思是生产者可以同时发送5条消息到broker并且等待响应。
       如果msg1和msg2同时发送后，msg1由于网络原因失败，如果配置了重试机制，则乱序。
  方法2
      使用幂等+重试：幂等保证record1没有成功前，record2会被broker抛弃； 重试机制保证了record2可以在record1成功后也成功。
  
### 高可用性 + 集群
- rabbitmq镜像集群

- kafka 
   HA机制，就是replica副本机制。每个partition的数据都会同步到其他机器上，形成自己的多个replica副本。然后所有replica会选举一个leader出来，那么生产和消费都跟这个leader打交道，然后其他replica就是follower
   
   
