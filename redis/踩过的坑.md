[性能排查手册](https://www.cnblogs.com/mushroom/p/4738170.html)

### 内存操作是0.1us, 磁盘操作是10ms，相差5个数量级；千兆网卡延时约0.2ms；

### 延时问题排查
- info stats 命令。信息里的total_commands_processed字段显示了Redis服务处理命令的总数
- Redis-cli --latency -h 127.0.0.1 -p 6379  查看client的延时时间
- 在客户端输入:slowlog get，默认命令执行时间超过10ms的记录
- 在Redis-cli工具中输入info clients 查看客户端连接数。默认最大1w。若是看到连接数超过5k以上，那可能会影响Redis的性能
- 配置最大客户连接数： 在redis.conf中配置maxclients， 超过则拒绝连接;

* 分析解决Redis性能问题，通常需要把延迟时间的数据变化与其他性能指标的变化相关联起来。
  命令处理总数下降的发生可能是由慢命令阻塞了整个系统;
  但如果命令处理总数的增加，同时内存使用率也增加，那么就可能是由于内存交换引起的性能问题
  
### 避免延时
* 管道命令
* 避免大集合操作

### 持久化问题
- 在没有开启持久化的情况下，redis宕机或者内存使用率超过95%会有丢数据的风险。
- 若使用快照(rdb)持久化，Redis会fork一个子进程把当前内存中的数据完全复制一份写入到硬盘上(fork使用的内存和redis当前使用的内存会一样多)。
  若是当前使用内存超过可用内存的45%时触发快照功能，那么此时进行的内存交换会变的非常危险(很可能会丢失数据)

### [常见丢数据的情况](https://blog.csdn.net/u012322399/article/details/80743173)
-  1.程序bug或人为误操作：误删除数据； DBA/RD误操作执行flushall/flushdb这类命令

-  2.因客户端缓冲区内存使用过大，超过maxmemory，触发redis的数据淘汰机制，导致数据丢失
    - 场景：
      假设一个Redis设置了maxmemory为4G，已经存储了2G数据，但是如果此时输出缓冲区使用了3GB，
      已经超过了maxmemeory限制，可能会产生数据丢失，键值淘汰，OOM等情况。
    - 基础知识：
      1.每个client都有queryBuffer，outputBuffer
      2.client缓冲区的内存消耗计算在used_memory内.
      3.client-output-buffer-limit：可以设置三种不同client： normal，slave，pubsub；
      4.buffer-limit3个值： hard limit size / soft limit size / soft limit second;
          只要客户端使用output buffer内存大小超过hard limit限制，redis会立即关闭此客户端；
          使用buffer内存大小超过soft limit，并且持续soft limit秒数，redis也会立即关闭此客户端。
    - 应对解决：
      1.业务容量规划时把缓冲正常消耗计算在内，合理设置maxmemory的限制(最好可预留几百M)；
      2.对输出缓冲区设置合理limit；如normal设置10MB, SLAVE设置1GB等。 如果复制因slave线程输出缓冲区反复同步，需临时调大slave client-output-buffer，要同时调大maxmemory限制。
    - 运维监控
      1.通过采集client list输出，并分别统计求各所有客户端的(qbuf+ qbuf-free)和omem,但性能消耗大
      2.使用info的clients section中的client_biggest_input_buf和client_longest_output_list两个指标来监控告警
      3.监控键的LRU驱逐数量：evicted_keys
      4.监控内存使用大小 used_memory
    - tips
      1.监控redis used_memory如果抖动严重，极有可能就是输出缓冲区过大。
      2.增加slave的limit限制，避免slave同步线程被杀，导致无限循环同步数据；且slave线程和挂载的slave个数相同，理论只有几个
      3.禁止生产环境使用monitor命令，在高QPS环境下，monitor很快会产生output query使用

-  3.主库故障后自动重启，可能导致数据丢失
    - 场景：
      1.时间点T1,主库故障关闭了，因设置有自动重启的守护程序，时间点T2主库被重新拉起；
      2.因(T2-T1)时间间隔过小，未达到Redis集群或哨兵的主从切换判断时长；
      3.这样从库发现主库runid变了或断开过，会全量同步主库rdb清理，并清理自己的数据。
      4.为保障性能,Redis主库往往不做数据持久化设置，那么时间点T2启动的主库，很有可能是个空实例（或很久前的rdb文件）。
    - 解决
      1 反对Redis粗暴地设置自动重启
      2 这种监控键个数的变化，缓存命中率，同时ELK类型准实时监控redis日志变化并告警
      
-  4.网络分区的问题，可能导致短时间的写入数据丢失
     - 场景：集群产生脑裂
         某种原因(网络原因)集群出现了分区，master与slave节点之间断开了联系，
         sentinel监控到一段时间没有联系认为master故障，然后重新选举，将slave切换为新的master。
         但是master可能并没有发生故障，只是网络产生分区，此时client任然在旧的master上写数据，而新的master中没有数据，如果不及时发现问题进行处理可能旧的master中堆积大量数据。
         在发现问题之后，旧的master降为slave同步新的master数据，那么之前的数据被刷新掉，大量数据丢失

-  5.主从复制数据不一致，发生故障切换后，出现数据丢失
    - 场景1：正常的主从复制出现过期时间不一致问题
       1.master有expire命令，那么同步到slave中，该命令将会被延迟执行
       2.master在做RDB快照文件的时候，发现key已经过期了，则此时不会将过期的key写到RDB文件中
       3.slave在load RDB文件到内存中的时候，发现key已经过期了，则此时不会将过期的key load进去
    - 应对解决场景1：
       1.针对问题1，采用expireat timestamp 方式，这样命令传送到从库就没有影响。
       2.针对问题23，做数据校验的时候会有些影响，因为key不一致，但不影响业务逻辑
       3.如果想key数量一致，把上场景23都改为不忽略过期key，过期key的删除统一由主库触发删除，然后将删除命令传送到从库中。这样key的数量就完全一致了
    - 场景2：异步复制同步丢失  
       - master还没来得及同步给slave节点时发生宕机
       - 要是master中开启持久化设置数据可不可以保证不丢失呢？答案是否定的。
          在master 发生宕机后，sentinel集群检测到master发生故障，重新选举新的master，
          如果旧的master在故障恢复后重启，那么此时它需要同步新master的数据，
          此时新的master的数据是空的（假设这段时间中没有数据写入）。那么旧master中的数据就会被刷新掉，此时数据还是会丢失
    - 应对解决：
       1.修改配置到合适值：min-slaves-to-write 1    min-slaves-max-lag 10
         表示至少有1个salve的与master的同步复制延迟不能超过10s，一旦所有的slave复制和同步的延迟达到了10s，那么此时master就不会接受任何请求。
       2.对于client，我们可以采取降级措施，将数据暂时写入本地缓存和磁盘中，在一段时间后重新写入master来保证数据不丢失；
        也可以将数据写入kafka消息队列，隔一段时间去消费kafka中的数据
    - 实战：
       [主从key数量不一致](https://www.jianshu.com/p/216cb17dc557)    
       [主从过期时间不一致](https://segmentfault.com/a/1190000013144617)
       
-  6.大量过期键，同时被淘汰清理
    - redis定期主动清理过期键，会导致Redis的键个数(dbsize)出现陡降(最大能达20%）。业务方常误以为有数据丢失。
    - 应对解决
       通过监控过期键淘汰的数量：expireed_keys的增长量，与dbsize键总数减少数据量是否相等。
    - 导致的一些奇怪现象：
       Master的键个数比Slave多20%； 高并发情况下，可能出现performance抖动,定期删除最坏可占25%的CPU时间片

### slave 与master发生连接断开，无限重连，无限同步问题
- client-output-buffer-limit slave 256mb 64mb 60
    这里对是客户端是slave的做限制，当output-buffer的大小大于256mb之后就会断开连接，大于64mb并且超过了60秒的时候就会断开连接
- repl-backlog-size(复制积压缓冲区是redis维护的固定长度环形缓冲队列)
* master的写入命令在同步给slaves的同时，会在缓冲区中写入一份(master只有1个积压缓冲区，所有slaves共享;
* 当redis复制中断后，slave会尝试采用psync, 上报原master runid + 当前已同步master的offset(复制偏移量，类似mysql的binlog file和position)；
* 如果runid与master的一致，且复制偏移量在master的复制积压缓冲区中还有(即offset >= min(backlog值)，master就认为部分重同步成功，不再进行全量同步，否则进行全量同步。


### 常见性能问题
1.rdb持久化，seve命令调度rdbsave函数，会阻塞主线程的工程，当快照比较大的时候对性能的影响是非常大的，会间断性暂停服务 。所以master最好不要写内存快照。
2.AOF持久化，如果不重写AOF文件，这个持久化方式对性能的影响是最小的，但是AOF文件会不断增大，AOF文件过大会影响master重启时的恢复速度。master最好不要做任何持久化工作，包括内存快照和AOF日志文件，特别是不要启用内存快照做持久化，如果数据比较关键，某个slave开启AOF备份数据，策略每秒为同步一次。
3.调用BGREWRITEAOF重写AOF文件，AOF在重写的时候会占大量的CPU和内存资源，导致服务load过高，出现短暂的服务暂停现象。
4.redis主从复制的性能问题，为了主从复制的速度和连接的稳定性，slave和master最好在同一个局域网内