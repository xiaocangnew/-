### 快的原因：
  * 单进程单线程
  * 完全基于内存
  * 数据结构简单
  * 使用多路i/o复用（I/O 多路复用模块）
  * 使用底层模型不同，Redis直接自己构建了VM机制，因为一般的系统调用系统函数的话，会浪费一定的时间去移动和请求；
- 单线程优点：
  * 代码清晰简单
  * 不存在切换cpu导致的开销
  * 不用考虑锁的问题，不用加锁和释放锁，没有因为死锁带来的性能消耗
- 单线程缺点：
  无法发挥多核cpu的优势，只能是单机多实例来完善。
  
- QPS 达到10w+
  在连接数为1w时，有8-9w的QPS；在连接数为3w时，依然有6w+的QPS； 在连接数为6w时，有5w的QPS，

### 虚拟内存
- redis为什么没有使用操作系统提供的虚拟内存而是在用户态实现了自己的虚拟内存机制？
* 操作系统最小单位为4k/页，而redis大多是小对象，所以一个操作系统页上有很多redis对象；
* redis的集合对象可能分布于多个操作系统页上，但只有10%的key经常被访问，但操作系统认为是活跃的，这样只有当内存真正耗尽才会进行页的交换
* 相对于操作系统，redis可以对对象进行压缩后再进行保存磁盘（10倍的样子），这样能减少io
    
- 虚拟内存相关配置：
    1.vm=enabled yes   开启虚拟内存
    2.vm-swap-file  /tmp/redis.swap   交换出来的value的保存路径和文件名
    3.vm-max-memory  268435456  内存上限达到后开始交换，建议为总内存的60%-80%
    4.vm-page-size 32    每个redis页的大小为32个字节
    5.vm-pages 134217728  多少个交换页，用来计算交换文件的最大值
    6.vm-max-threads 8  用于执行交换操作的线程。0表示用主线程进行交换，这是阻塞的，不利于相应
    
### redis内存模型
* 主进程本身运行肯定需要占用内存，如代码、常量池等
* 内存碎片不算到used_memory中；
* used_memory = 缓冲内存(客户端缓冲区、复制积压缓冲区、AOF缓冲区) + redis存储的数据；

- 内存占用查看
* used_memory：Redis分配器分配的内存总量
* used_memory_rss：总内存占用(= 系统开销 + used_memory + 内存碎片)
* mem_fragmentation_ratio：内存碎片比率(=used_memory_rss / used_memory； 比率稍>1合理；>1.5内存碎片率大，<1正在进行swap)
* mem_allocator：Redis使用的内存分配器，在编译时指定；可以是libc\jemalloc\tcmalloc，默认是jemalloc

### 高并发下如何保证缓存和数据库的数据一致性
- 常用的缓存读写模式(https://stephanietang.github.io/2020/04/13/cache-pattern/)
    - cache aside
    - read-through / write-through
    - write back
    - write around
- 解决方案：
    - 先更新缓存，后更新数据库
        这种策略纯属凑数，应该没人会这么使用
    - 先更新数据库，后更新缓存(T1T2写库)
        多线程导致出现的脏数据： T1 更新库--> T2更新库--> T2更新缓存--> T1更新缓存
    - 先删除缓存，后更新数据库(T1读，T2写库)
        多线程中可能导致脏数据: T1写线程删除缓存 -> T2读线程获取不到缓存 -> T2读线程重新从DB构建缓存 -> T1更新DB
        - 解决脏数据策略： 延时双删策略 
    - (推荐策略)先更新数据库，后删除缓存 (T1读，T2写库) 
        - 多线程中可能导致脏数据: 缓存失效-> T1 请求数据库得到旧值 --> T2更新数据库 --> T2删除缓存 --> T1 将旧值load到缓存
        - 虽然可能有并发问题，但是概率非常小，因为只有当T2更新数据库的时间小于T1读数据库的时间时，才可能发生T2删除缓存比T1 load旧值先发生；
            - 如果小概率事件发生了怎么办：
                - 给缓存设置过期时间(保证最终一致性)；
                - 采用延时双删策略 : 1. 删除缓存--> 写库 --> sleep(500MS) --> 删除缓存,  同时设置合理的过期时间(sleep时间判断： 在读数据业务逻辑的耗时基础上，加几百ms即可。确保读请求结束，写请求可以删除读请求造成的缓存脏数据)
            - 如果删除缓存失败了怎么办：
                - 提供保障重试机制: 使用一个队列存放删除失败的key，消费这个队列；    
    - 异步更新缓存，采用canal
        redis缓存读数据， mysql 负责写数据，更新由canal负责；
    - 串行化(终级解决方案)
        1. 先删缓存，将更新数据库的操作放进有序队列中 2. 从缓存查不到的查询操作，都进入有序队列
      串行化需要解决的问题：
         读请求积压，大量超时，导致数据库的压力：限流、熔断
         如何避免大量请求积压：将队列水平拆分，提高并行度。
         保证相同请求路由正确。
### 数据淘汰机制：
- 当内存使用达到设置的最大阀值95%时，内存的数据会开始和磁盘产生频繁的交换 (swap，慢5个数量级)。交换会让Redis的性能急剧下降
  当内存数据集大小达到一定的大小时，redis就会根据maxmemory-policy配置项配置的策略来进行数据淘汰。
* 从设置过过期时间的数据集中：  volatile-lru算法，volatile-random算法，volatile-ttl算法（time to live）
* 从全数据集中：allkeys-lru算法，allkeys-random算法，noeviction永不过期。   

- 使用策略规则：
1.如果数据分为冷数据和热数据，也就是一部分数据访问频率高，一部分数据访问频率低。则使用allkeys-lru
2.如果数据呈现平等分布，也就是所有的数据访问频率都相同，则使用allkeys-random
3.或者写一个定时任务，定期将高频数据同步到redis中

- 注意
  使用expire time会消耗额外内存。

- 如何配置
* 修改redis.conf的maxmemory，设置最大使用内存：maxmemory 1024000
* 修改redis.conf的maxmemory-policy，设置redis缓存淘汰机制： maxmemory-policy noeviction

- 如何查看
* info stats。信息中的evicted_keys字段显示的是被回收删除的keys数量

### redis采用的过期策略   redis采用懒惰删除 + 定期删除结合方式
- 业界对于过期一般有3中策略：
* 定时删除--为key创建timer---保证内存及时释放---占用cpu来跑timer，创建timer耗时
* 懒惰删除--当使用key时才判断是否过期然后删除--占用cpu少，因为只删除当前key ---可能发生内存泄漏
* 定期删除--每隔一段时间执行一次删除过期key操作--优缺点都剧中---难点：定期时长的选择，游标的记录位置保存
   - 定期删除流程：
     1.Redis每秒调用10次(hz参数决定)activeExpireCycle函数；
     2.每次随机获取20个带有生存时间的键。
     3.删除其中已过期的键。
     4.如果其中过期键超过25%(即大于5个键是过期的),activeExpireCycle函数会重新调用，
      开始第一步(如果大量KEY同时过期，可能引起Redis性能抖动)。

- 大量过期键堆积，最直接影响是浪费内存空间；另外还会有些”灵异现象”
   1.Master的键个数比Slave多20%
   2.读定分离时，应用程序读取Slave时能返回快过期的键
   3.Redis scan或keys出来的键个数，远小于dbsize返回的个数
   4.高并发情况下，可能出现性能抖动,定期删除最坏可占25%的CPU时间片
   
- 从两个方面解决大量过期键
    - 降低过期键产生的速度；
       1.业务设计键的过期时长时，是否考虑过期键生成的速度；能否加大过期键的生存时间。 如天气缓存集群，大量的键要求1分钟过期，从产品需求角度，能否设置更大。
       2.尽量避免使用大实例，控制Redis单实例的键个数(如1kw)，可有效控制单个实例过期键产生的速度；拆分为更多的分片，加大集群定期删除的速度
    - 加快定期删除的速度。
       1.适当调大hz的值,增大每秒定期删除的次数；建议调整60，官方建议小100； 因调用serverCron除了过期删除动作外，还有很多其他操作，可能占用过多的CPU时间片
       2.主动触发Redis”惰性删除策略”,通过scan命令扫描整个实例的键，Redis会删除所有已过期的键。

### 持久化
* 手动触发：   lastsave 指令可以查看最近的备份时间
   - SAVE：阻塞Redis的服务器进程，知道RDB文件被创建完毕
   - BGSAVE：Fork出一个子进程来创建RDB文件，不阻塞服务器进程 
* RDB半持久化(默认):不定期的通过异步方式(BGSAVE)保存到磁盘上.(redis database，)
  - 没有高可用，但是性能更好。有利于灾难恢复，启动时效率跟高
  - 配置：rdb save 900 1 ;每900秒后，如果至少一个key变化，dump
* AOF全持久化:每一次数据变化都异步地写入到一个append only file(aof)里面
  - 能保持高可用，但是性能低点，相同数据量时aof文件比rdb文件更大
  - 配置：aof  appendfsync always//everysec//no
  
- RDB对性能的影响，有什么方法可以规避吗？
   1.每次保存 RDB 的时候，Redis 都要 fork() 出一个子进程，并由子进程来进行实际的持久化工作。  
   2.在数据集比较庞大时，fork()可能会非常耗时，造成服务器在某某毫秒内停止处理客户端；如果数据集非常巨大，并且CPU时间非常紧张的话，那么这种停止时间甚至可能会长达数秒。
   3.通常的设计思路是利用Replication机制来弥补RBD性能上的不足，达到了数据可持久化。
      即Master上RBD和AOF都不做，来保证Master的读写性能，而Slave上则同时开启RBD和AOF来进行持久化，保证数据的安全性。
  
  
###主从复制 (同步机制)
- 初始化时执行全量同步
1）slave-->发送PSYNC命令-->master
2）master-->BGSAVE命令-->生成RDB文件 + 缓冲区记录此后执行的所有写命令；
3）BGSAVE执行完后，master-->rdb文件-->slave + 继续记录被执行的写命令；
4）slave-->收到rdb-->丢弃旧数据 + load rdb；
5）slave-->rdb处理完毕-->发信号到master，master发送缓冲区中的写命令；
6）slave-->rdb载入ok-->开始接收命令请求 + 执行来自master缓冲区的写命令；

- 正常工作时执行增量同步(命令传播)
* master每执行一个写命令就会向slave发送相同的写命令，slave接收并执行收到的写命令
   
- sync 和 psync
   - redis2.8以前用的时sync，对于slave断线重连master，需要重新全量复制master，即使是很小的时间间隔，带来巨大的浪费；
   - redis2.8以后，使用psync替代sync， psync有完整同步和部分同步功能；
      - 基础概念
         1.主服务器的复制偏移量( replication offset )和从服务器的复制偏移量。
         2.主服务器的复制积压缓冲区(replication backlog)--- master在把命令给slave时，也会放入积压缓冲区中。slave断线重连复制时，如果offset偏移量之后的数据还在积压缓冲区中，则进行部分复制
         3.服务器的运行ID(run ID)。 slave对应的master如果runId相同，则进行部分复制，否则全量复制

- 注意
* slave在同步未完成时使用老数据
* BGSAVE命令 = fork子进程 + copy on write
      - copy on write 原理
           fork()之后，kernel把父进程中所有的内存页的权限都设为read-only，然后子进程的地址空间指向父进程。
           当父子进程都只读内存时，相安无事。当其中某个进程写内存时，CPU硬件检测到内存页是read-only的，
           于是触发页异常中断（page-fault），陷入kernel的一个中断例程。中断例程中，kernel就会把触发的异常的页复制一份，于是父子进程各自持有独立的一份
      - copy on write 优缺点
           优点是：减少分配和复制大量资源时带来的瞬时延迟， 减少不必要的资源分配；
           缺点是：如果fork后父子进程都还需要进行写操作时，就会产生大量的分页错误；(总体来看，Redis还是读操作比较多)
* redis使用异步方式进行数据同步，是弱一致性的，但是性能比同步方式好

### 集群
- 一个集群只能有16384个槽，编号0-16383。这些槽会分配给集群中的所有主节点，分配策略没有要求
- 查询key时，集群已经发生了变化，客户端的缓存还没来得及更新。则查询类似http302的重定向。

### sentinel
- 应用程序连接到哨兵端口，通过指定不同的master名称连接到具体的主副本。
- 哨兵的作用：
* 监控 
* 通知
* 自动故障转移 ：将失效Master的其中一个Slave升级为新的Master, 并让失效Master的其他Slave改为复制新的Master
* 配置提供者： redis使用sentinel的配置
 
- sentinel 节点个数至少要有三个， 只有一个会造成单点， 两个的话无法选举。


### redis高可用方案
* 1.单点
* 2.主从
  - 优点：
  1)高可靠性：一方面，采用双机主备架构，能够在主库出现故障时自动进行主备切换，从库提升为主库提供服务，保证服务平稳运行；另一方面，开启数据持久化功能和配置合理的备份策略，能有效的解决数据误操作和数据异常丢失的问题。
  2)读写分离策略：从节点可以扩展主库节点的读能力，有效应对大并发量的读操作。
  - 缺点： 
  1)故障恢复复杂，如果没有 Redis HA 系统（需要开发），当主库节点出现故障时，需要手动将一个从节点晋升为主节点，同时需要通知业务方变更配置，并且需要让其他从库节点去复制新主库节点，整个过程需要人为干预，比较繁琐。
  2)主库的写能力受到单机的限制，可以考虑分片。
  3)主库的存储能力受到单机的限制，可以考虑 Pika。
  4)原生复制的弊端在早期的版本中也会比较突出，如：Redis 复制中断后，Slave 会发起 psync，此时如果同步不成功，则会进行全量同步，主库执行全量备份的同时可能会造成毫秒或秒级的卡顿。
  5)又由于COW机制，导致极端情况下的主库内存溢出，程序异常退出或宕机；主库节点生成备份文件导致服务器磁盘 IO 和 CPU（压缩）资源消耗；发送数 GB 大小的备份文件导致服务器出口带宽暴增，阻塞请求，建议升级到最新版本。
* 3.哨兵模式(侧重高可用)
  - 优点：
   1)部署简单；
   2)能够解决主从模式下的高可用切换问题；
   3)方便实现 Redis 数据节点的线性扩展，轻松突破 Redis 自身单线程瓶颈，满足大容量或高性能的业务需求；
   4)可以实现一套 Sentinel 监控一组 Redis 数据节点或多组数据节点。
  - 缺点：
   1)部署相对主从模式要复杂一些，原理理解更繁琐；
   2)资源浪费，slave节点作为备份节点不提供服务；
   3)主要是针对master的高可用做切换，对slave做SDOWN下线操作（不做ODOWN），并不执行故障转移。
   4)不能解决读写分离问题，实现起来相对复杂。
   - 建议
   如果监控同一业务，可以选择一套 Sentinel 集群监控多组 Redis 数据节点的方案，反之选择一套 Sentinel 监控一组 Redis 数据节点的方案。
   sentinel monitor <master-name> <ip> <port> <quorum> 配置中的<quorum>建议设置成 Sentinel 节点的一半加 1，当 Sentinel 部署在多个 IDC 的时候，单个 IDC 部署的 Sentinel 数量不建议超过（Sentinel 数量 – quorum）。
   合理设置参数，防止误切，控制切换灵敏度控制：
   a. quorum
   b. down-after-milliseconds 30000
   c. failover-timeout 180000
   d. maxclient
   e. timeout
   部署的各个节点服务器时间尽量要同步，否则日志的时序性会混乱。
   Redis 建议使用 pipeline 和 multi-keys 操作，减少 RTT 次数，提高请求效率。
   自行搞定配置中心（zookeeper），方便客户端对实例的链接访问。

* 4.cluster(侧重扩展)
  - 优点
   1)无中心架构；
   2)数据按照 slot 存储分布在多个节点，节点间数据共享，可动态调整数据分布；
   3)可扩展性：可线性扩展到1000多个节点，节点可动态添加或删除；
   4)高可用性：部分节点不可用时，集群仍可用。通过增加Slave做主备模式下的备机，能够实现故障自动failover，节点之间通过gossip协议交换状态信息，用投票机制完成Slave到Master的角色提升；
   5)降低运维成本，提高系统的扩展性和可用性。
  - 缺点：
   1)Client 实现复杂，驱动要求实现 Smart Client，缓存 slots mapping 信息并及时更新，提高了开发难度，客户端的不成熟影响业务的稳定性。目前仅 JedisCluster 相对成熟，异常处理部分还不完善，比如常见的“max redirect exception”。
   2)节点会因为某些原因发生阻塞（阻塞时间大于 clutser-node-timeout），被判断下线，这种 failover 是没有必要的。
   3)数据通过异步复制，不保证数据的强一致性。
   4)多个业务使用同一套集群时，无法根据统计区分冷热数据，资源隔离性较差，容易出现相互影响的情况。
   5)Slave 在集群中充当“冷备”，不能缓解读压力，当然可以通过 SDK 的合理设计来提高 Slave 资源的利用率。
   6)Key 批量操作限制，如使用 mset、mget 目前只支持具有相同 slot 值的 Key 执行批量操作。对于映射为不同 slot 值的 Key 由于 Keys 不支持跨 slot 查询，所以执行 mset、mget、sunion 等操作支持不友好。
   7)Key 事务操作支持有限，只支持多 key 在同一节点上的事务操作，当多个 Key 分布于不同的节点上时无法使用事务功能。
   8)Key 作为数据分区的最小粒度，不能将一个很大的键值对象如 hash、list 等映射到不同的节点。
   9)不支持多数据库空间，单机下的 redis 可以支持到 16 个数据库，集群模式下只能使用 1 个数据库空间，即db0 。
   10)复制结构只支持一层，从节点只能复制主节点，不支持嵌套树状复制结构。
   11)避免产生 hot-key，导致主库节点成为系统的短板。
   12)避免产生 big-key，导致网卡撑爆、慢查询等。
   13)重试时间应该大于 cluster-node-time 时间。
   14)Redis Cluster 不建议使用 pipeline和multi-keys 操作，减少 max redirect 产生的场景。
  - 在客户端实现负载均衡
    1.随机 /hash算法 /轮询   适用于各个机器性能相当
    2权重轮询
    3.响应速度均衡   减少任务堆积
    4.最少连接数均衡   
* 5.自研

### 缓存穿透（恶意穿透引起）
1.缓存空值，但是它的过期时间设置的比较短
2.bloomFilter 布隆过滤器，
    优点: 思路简单  /保证一致  /性能强 
    缺点: 代码复杂度增大 /需要另外维护一个集合来存放缓存的Key /布隆过滤器不支持删值操作

### 缓存雪崩(大量key同时过期)
1.为有效期增加随机值/统一规划有效期，使失效时间均匀分布
2.使用互斥锁，只用一个线程去查询db，其他线程等待；
3.限流+降级，避免mysql 挂掉

### 缓存击穿(热点key过期)
1. 使用互斥锁(mutex key):只让一个线程构建缓存，其他线程等待构建缓存的线程执行完
2. 提前使用互斥锁(mutex key)：在value内部设置1个超时值(timeout1), timeout1比实际的timeout(timeout2)小。当从cache读取到timeout1发现它已经过期时候，马上延长timeout1并重新设置到cache。然后再从数据库加载数据并设置到cache中。
3. "永远不过期"：不设置过期时间
  我们把过期时间存在key对应的value里，如果发现要过期了，通过一个后台的异步线程进行缓存的构建，
4. 资源保护：例如hystrix，但有降级的问题。

- 永不过期demo（异步构建缓存）
    在这种方案下，构建缓存采取异步策略，会从线程池中取线程来异步构建缓存，从而不会让所有的请求直接怼到数据库上。
    该方案redis自己维护一个timeout，当timeout小于System.currentTimeMillis()时，则进行缓存更新，否则直接返回value值。
集群环境的redis代码如下所示:
``````
String get(final String key) {  
        V v = redis.get(key);  
        String value = v.getValue();  
        long timeout = v.getTimeout();  
        if (v.timeout <= System.currentTimeMillis()) {  
            // 异步更新后台异常执行  
            threadPool.execute(new Runnable() {  
                public void run() {  
                    String keyMutex = "mutex:" + key;  
                    if (redis.setnx(keyMutex, "1")) {  
                        // 3 min timeout to avoid mutex holder crash  
                        redis.expire(keyMutex, 3 * 60);  
                        String dbValue = db.get(key);  
                        redis.set(key, dbValue);  
                        redis.delete(keyMutex);  
                    }  
                }  
            });  
        }  
        return value;  
    }  
``````

### 使用过Redis做异步队列
- 使用list结构作为队列， 使用lpush , lpop, blpop

### redis如何实现延时队列
- 使用sortedset，拿时间戳作为score，消息内容作为key调用zadd来生产消息，消费者用zrangebyscore指令获取N秒之前的数据轮询进行处理。

###如果有大量的key需要设置同一时间过期，一般需要注意什么？
   如果大量的key过期时间设置的过于集中，到过期的那个时间点，redis可能会出现短暂的卡顿现象。一般需要在时间上加一个随机值，使得过期时间分散一些。
   
### 分布式锁
1. setnx,会有死锁问题，线程在未设置expireTime就异常，则永远无法释放锁；
2. 使用jedis.set(lockKey, requestId, "NX", "PX", expireTime); // requestId用来保证分布式锁的解铃还须系铃人
2. 使用lua脚本，通过一次执行保证。

###如果突然机器掉电会怎样？
取决于aof日志sync属性的配置，如果不要求性能，在每条写指令时都sync一下磁盘，就不会丢失数据。
但是在高性能的要求下每次都sync是不现实的，一般都使用定时sync，比如1s1次，这个时候最多就会丢失1s的数据。

### redis 如何保证高并发
1. Redis通过主从架构，实现读写分离，主节点负责写，并将数据同步给其他从节点，从节点负责读，从而实现高并发。
2. 如果缓存要容纳的数据量很大，需要使用redis集群

### redis的并发竞争
1. redis本身是单线程的，并不存在并发竞争的问题；
2. redis连接多客户端，可能同时修改某个key，导致竞争；
3. 分布式锁+时间戳方案： 只有获得锁的进程才能取更新redis，同时更新时带上数据库的时间戳，如果redis中的值比数据库中的值新，就不更新；

### redis的CAS乐观锁
- 乐观锁介绍：
    watch指令在redis事物中提供了CAS的行为。为了检测被watch的keys在是否有多个clients同时改变引起冲突，这些keys将会被监控。
    如果至少有一个被监控的key在执行exec命令前被修改，整个事物将会回滚，不执行任何动作，从而保证原子性操作，并且执行exec会得到null的回复。
- 乐观锁工作机制：
    watch命令会监视给定的每一个key，当exec时如果监视的任一个key自从调用watch后发生过变化，则整个事务会回滚，不执行任何动作。
    注意watch的key是对整个连接有效的，事务也一样。如果连接断开，监视和事务都会被自动清除。
    当然exec，discard，unwatch命令，及客户端连接关闭都会清除连接中的所有监视。
    还有，如果watch一个不稳定(有生命周期)的key并且此key自然过期，exec仍然会执行事务队列的指令。
    
### 哨兵机制原理