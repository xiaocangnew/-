### innodb和myIsam引擎对比（都是用b+树）
- 事务处理不同
    MyISAM不支持事务，而InnoDB支持事务
- 锁机制不同
    MyISAM是表级锁，而InnoDB是行级锁；
- 索引机制不同
    MyISAM使用非聚簇索引，索引和数据存储是分开的； innodb使用聚簇索引，数据文件本身就是索引文件；
- 主键
    MyISAM可以没有主键， 
    innodb必须有(数据文件本身要按主键聚集);
      1. 定义了主键(PRIMARY KEY)，那么InnoDB会选择其作为聚集索引；
      2. 没有显式定义主键，则InnoDB会选择第一个不包含有NULL值的唯一索引作为主键索引；
      3. 如果也没有这样的唯一索引，则InnoDB会选择内置6字节长的ROWID作为隐含的聚集索引
       (ROWID随着行记录的写入而主键递增，是隐含的，效率很低)。
- 外键支持   
    mysiam表不支持外键，而InnoDB支持
    
### innodb引擎的4大特性
插入缓冲（insert buffer),
二次写(double write),
自适应哈希索引(ahi),
预读(read ahead)

### [存储结构](https://blog.csdn.net/chenjiayi_yun/article/details/45533909)
* 从物理意义上来讲，InnoDB表空间组成：
   - 共享表空间文件（ibdata1，最大64Tb):数据库的所有的表数据，索引文件全部放在一个文件中
   - 独占表空间文（ibd，受限文件系统）: ibd文件 = 单一表数据+索引
   - 表结构文件（.frm）：保存每个数据表的元数据(meta)信息，包括表结构的定义
   - 日志文件（redo文件）

* 从系统意义上来讲，InnoDB表空间（Tablespace）: 由分散的段(Segment)组成。
   - 段(Segment)包含多个区（Extent）。
   - 区（Extent）由64个连续的页（Page）组成，
   - 页大小为16K   (数据页、Undo页、系统页、事务数据页、插入缓冲位图页、以及插入缓冲空闲列表页)
   
### [日志系统]()
- 错误日志： --log-err 默认host_name.err
- 查询日志： --log 默认名host_name.log
- 慢查询日志: -log-slow-queries  默认名host_name.-slow.log
- 二进制日志(记录数据修改)： -log-bin
   * 恢复数据
      - 使用事件时间的时间点恢复 --start-datetime  --stop-datetime
      - 使用事件位置的时间点恢复 --start-position  --stop-position
        shell> mysqlbinlog --stop-datetime="2017-04-20 9:59:59" /var/lib/mysql/mysql-bin.000001 | mysql -u root -p  
        shell> mysqlbinlog --start-datetime="2017-04-20 10:01:00" /var/lib/mysql/mysql-bin.000001 | mysql -u root -p  
      - 查询时间段内日志的执行内容
        mysqlbinlog --start-datetime='2018-01-08 02:01:00' --stop-datetime='2018-01-08 02:30:10' -d test /var/lib/mysql/mysql-bin.000170 -v (|grep DELETE -A 5)
   * 日志录入格式：
      - Statement：每一条会修改数据的sql都会记录在binlog中
      - Row:不记录sql语句上下文相关信息，仅保存哪条记录被修改。
      - Mixedlevel: 是以上两种level的混合使用
      - statement 可能占用空间会相对小一些，传送到 slave的时间可能也短，但是没有row模式的可靠
      
- 事务日志 undo-log; redo-log; undo/redo-log

* 是否启用了日志 ：show variables like 'log_%';
* 怎样知道当前的日志 ：show master status;
* 显示二进制日志数目 ： show master logs;
* 看二进制日志文件用
   shell> mysqlbinlog mail-bin.000001
   shell> mysqlbinlog mail-bin.000001 | tail
   
###在 InnoDB 引擎中有三种数据类型索引：
- B-Tree 索引
   使用B+树数据结构
- 哈希索引
- 全文索引 (5.6才支持innodb， 5.7 支持中文)
   全文索引是一种比较特殊的索引，一般都是基于倒排索引来实现的
   倒排索引的数据结构：在辅助表中存储了单词与单词自身在一个或多个文档中所在位置的映射
   当索引失效后会走全文索引
   
### hash索引
- Hash索引底层是哈希表，哈希表是一种以key-value存储数据的结构(value存储的是行指针)，所以多个数据在存储关系上是完全没有任何顺序关系的
  索引结构非常紧凑，与B树索引相比，单行查询更快。
1. 哈希索引‘适合等值查询’，
- 缺点
1. 但是无法进行范围查询 
2. 哈希索引没办法利用索引完成排序 
3. 哈希索引不支持多列联合索引的最左匹配规则 
4. 如果有大量重复键值的情况下，哈希索引的效率会很低，因为存在哈希碰撞问题
   
### 存储结构 ：使用B+树存储；
- 聚集索引
   聚集索引就是根据主键来构造 B+ 树，叶子节点存放对应页的行记录。
- 辅助索引（非聚集索引）
  辅助索引就是使用非主键构造的 B+ 树，叶子节点存放的是对应的键值以及相应的聚集索引键。
  通过辅助索引来搜索一般是两级的，第一级找到键值对应的聚集索引键，第二级是根据聚集索引键寻找行记录。
- 联合索引
   联合索引就是对表上的多个列进行索引，这样构造的 B+ 树的 Index Node 和 Page Node 包含多个键。
   
- 为什么不使用B树存储？
  - 1.因为B+树的分支结点并不会存储关键字的具体信息，只存储索引，所以相较于B树也较小；
      因此一次I/O操作所能够容纳的关键字就多一些，那么读取一个结点的I/O操作次数也就少一些；
      索引的B+树高度一般为2-4层，查找记录时最多只需要2-4次IO。
  - 2.B+树的所有具体信息都存储在叶子结点，通常都会使用链表将叶子结点连接起来，
      遍历叶子结点就能够获取到所有的数据，就可以进行区间查询，B树只有中序遍历才能够获取到所有的数据
      (例如查找大于等于3的数据，当在叶子节点中查到3时，通过3的尾指针便能获取所有数据，而不需要再像二叉树一样再获取到3的父节点)
  - 所以，通常B+树用于数据库索引，而B树则常用于文件索引。

- 读磁盘
  1. 程序的局部性原理，使用预读，提前准备好要用数据，提升I/O效率
  2. 计算机存储最小单元：扇区(512字节)； 文件系统最小单元：块(4k); innodb最小存储单元： 页(16k)
  3. 预读的长度一般为页（page）的整倍数，主存和磁盘以页为单位交换数据
  4. 磁盘预读是以页为单位的，所以一页就代表访问一次磁盘(一次I/O操作)。
  5. 设计中把一个节点设为一页。(节点就是理解的二叉树的节点或者b树的节点；);
  6. 单个叶子节点（页）中的可以存储的：
       数据个数(一个数据项默认为1k):16K/1K=16个数据
       索引个数(一个索引数据为16字节)：16 * 1024byte/16byte=1170个
  7. 在3层高的1001阶树上，存储的节点有 1 + 1001 + 1001*1000 = 100万个

- 为什么不使用红黑树
  - 红黑树的阶数更大，B树更短，这样查找的时候B树更具有优势了，效率也就越高。
  - 当用红黑树的时候(二叉树)，一次只能得到一个键值的信息，而用B树(M阶树)，可以得到最多M-1个键值的信息；
    由于计算机局部性原理，B树更好
    
### 事务  
- 事务是如何实现的 
   两阶段提交保证事务。
- 事务的ACID属性
   1. atomic 原子性： 事务中的操作要么全完成，要么都不完成；
   2. consisdence 一致性： 事务必须是数据库从一个一致性状态变到另一个一致性状态。
   3. isolation 隔离性： 同一时间，只允许一个事务请求同一数据
   4. duration： 持久性： 事务完成后，事务对数据库的所有更新将被保存到数据库
- 事务有ACID属性，所以就是如何保证这几个特性就可以实现事务。
   - 隔离性由锁来保证。
   - 一致性由undo-log来保证，可以做事务回滚和MVCC的功能。
   - 原子性与持久性由redo-log来保证。
- 事务的隔离级别  select @@tx_isolation 默认可重复度，有幻读问题
  * 未提交读R：有脏读问题:就是指事务T1读取了事务T2未提交的数据
  * 提交读RC：没有脏读问题; 有不可重复读问题:T1读取a-->T2修改a，然后commit--> T1再次读取a
  * 可重复读RR：没有不可重复问题; 有幻读问题:T1读取a1-a2两条记录-->T2插入a1.5，然后commit--> T1再次读取,a1-a2，这时有3条记录
  * 序列化读S：没有幻读问题。可能导致大量的超时现象和锁竞争
- 锁释放
  1. 在事务执行过程中，如果有加锁操作(增改删)，这个锁需要等事务提交时释放。
  2. 对于查询语句，只要查询完成就会释放共享锁，而不必等待事务结束，且和事务隔离级别无关
- 事务加锁
  1. 加锁操作是加在索引上的，如果不走索引，则锁表。


- mysql如何实现可重复读
     - 使用MVCC机制(多版本并发控制)解决，但是不彻底：
        1. 在MySQL可重复读的隔离级别中，读数据是没有幻读问题的。(select使用快照读，T1读取的是快照)
        2. 在MySQL可重复读的隔离级别中，先更新数据后，读数据有幻读问题的。(对于会对数据修改的操作(update、insert、delete)都是采用当前读的模式)
        在执行修改数据操作时会读取最新的版本号记录，写操作后把版本号改为了当前事务的版本号，select时也用了最新的版本号，所以其他事务的提交可以看到。
        3. 解决更新时的幻读问题：
            3.1. 使用序列化读。
            3.2. 使用next-key lock。会锁定范围和自身行。 使用方式： select for update / select in share mode， 会阻塞其他事务修改。
   
- MVCC
   - 工作在提交读和可重复读下
   - 原理
      InnoDB的MVCC,是通过在每行记录后面保存两个隐藏的列来实现的,这两个列：行创建版本号，行的删除版本号。
      每开始一个新的事务，版本号就会自动递增，事务开始时刻的系统版本号会作为事务的ID
   - 增删查改
      1. 插入: 记录的版本号即当前事务的版本号
      2. 更新: 先标记旧的那行记录为已删除，并且删除版本号是事务版本号，然后插入一行新的记录的方式
      3. 删除: 把事务版本号作为删除版本号
      4. 查询： 只能查询比自己事务版本号小的创建行； 只能查询比自己大的删除版本号行;
      
### [锁](https://blog.csdn.net/varyall/article/details/80219459)

InnoDB是基于索引来完成行锁

innodb锁信息查询时：
- lock_type:  
    - 表锁 lock table xxx read/write
    - 行锁 : LOCK_ORDINARY / LOCK_GAP / LOCK_INSERT_INTENTION / LOCK_REC_NOT_GAP
- lock_mode: 
    lock_ix, lock_is, lock_x, lock_s, auto
     
- 行级锁
  - record lock ：单纯的锁在记录上
  - gap lock：只锁住一段范围，不锁记录本身，通常表示两个索引记录之间：可重复读RR级别下；
     - INSERT INTENTION LOCK 插入意向锁是GAP锁的一种,在insert操作时产生。
         在多事务同时写入不同数据至同一索引间隙的时候，并不需要等待其他事务完成，不会发生锁等待
         插入意向锁之间不冲突，但是插入意向锁和Next-Key Lock、GAP LOCK冲突，也正是这种冲突，阻止了记录的插入，从而避免了幻读
     - 间隙锁是一个在索引记录之间的间隙上的锁 （没有建立索引或者是非唯一索引时，则语句会产生间隙锁）
     - 当使用唯一索引来搜索唯一行的语句时，不需要间隙锁定，只需要record lock
     - gap锁之间不冲突。但是next_key锁之间冲突，因为next_key里的record_lock冲突。
  - next_key lock
     - record lock + gap lock， 正是为了解决RR隔离级别下的幻读问题
     - 在RR隔离级别下，locking reads，UPDATE和DELETE时，除了对唯一索引的唯一搜索外都会获取gap锁或next-key锁
     - lock_gap VS lock_next_key
        如果where条件中的sql列命中记录，则使用next_key,否则使用gap锁；
     - 当查询的索引含有唯一属性的时候，Next-Key Lock 会进行优化，将其降级为Record Lock;
  - lock_s： 其他事务可以读取，但不可以修改
  - lock_x(排他锁) 通常对于UPDATE或者DELETE操作，或者类似SELECT … FOR UPDATE操作，都会对记录加排他锁
  
- 表级锁
   - Intention lock意向锁(事务在请求S锁和X锁前，需要先获得对应的IS、IX锁)
      1. LOCK_IS, LOCK_IX两种
      2. 意向锁的存在是为了协调行锁和表锁的关系，支持多粒度（表锁与行锁）的锁并存
         例子：事务A修改user表的记录r，会给记录r上一把行级的排他锁（X），同时会给user表上一把意向排他锁（IX），
              这时事务B要给user表上一个表级的排他锁就会被阻塞。意向锁通过这种方式实现了行锁和表锁共存且满足事务隔离性的要求。
      3. 意向锁相互兼容
      4.为什么意向锁是表级锁
        当我们需要加一个排他锁时，需要根据意向锁去判断表中有没有数据行被锁定（行锁）；
        （1）如果意向锁是行锁，则需要遍历每一行数据去确认；  
        （2）如果意向锁是表锁，则只需要判断一次即可知道有没数据行被锁定，提升性能。
  - LOCK_AUTO_INC
  
- 在update/delete时，如果是非唯一索引，需要先锁住非唯一索引，然后再根据聚簇索引锁住主键列
[](https://zhuanlan.zhihu.com/p/110206371?from_voters_page=true)
  
  
### 索引
- 索引分类
    - 聚簇索引： 使用B+树， 非叶子节点为主键id， 叶子节点为数据；
        ‘表数据存储’按照‘索引的顺序’来，也就是说索引项的顺序与表中记录的物理顺序一致，一张表只能有一个；
    - 非聚簇索引： 使用B+树， 非叶子节点为索引列， 叶子节点为主键id；
        表数据存储顺序与索引顺序无关。
- 索引优化
    * 常见优化方向
       - 设计时注意：
          1. 最左前缀匹配原则：一个查询可以只使用索引中的一部份，但只能是最左侧部分
          2. 尽量选择区分度高的列作为索引,区分度的公式是count(distinct col)/count(*)，
          3. 索引要建立在经常进行select操作的字段上
       - 不走索引的情况
          1. 有索引，1.1不符合最左前缀原则；1.2 模糊搜索时使用了前缀模糊。
          2. 联合索引的最左前缀中， 如果出现'>'或者'<'，那么这列是走索引的最后一列，之后的查询条件都不走索引了。
             '>='或者'<='之后的列可以继续走索引。
          3. where中使用不等号(!=或<>操作符)时， 只有在主键或唯一索引时会走，普通索引不走。          
          4. 索引列使用了函数或参与运算
          5. 数据类型出现隐式转化（如varchar不加单引号的话可能会自动转换为int型） 
          6. where语句里面如果带有or条件, myisam表能用到索引， innodb不行(如果必须使用，推荐使用union或者in查询都可以走索引)
          7. 两个表使用的编码不一样，则不走索引
       - sql优化
          1. 避免使用select *, 使用具体字段；
          2. 避免使用in 和 not in，or， null值判断；
          3. 当我们执行查询的时候，MySQL只能使用一个索引。如果你有三个单列的索引，MySQL会试图选择一个限制最严格的索引。
       - group by中索引情况；
          1. 使用where子句和order by子句的组合满足最左前缀原则。
          2. order by 子句单独使用索引并满足最左前缀原则。
          3. order by key_part1 asc, key_part2 desc 不走索引。 当都是asc时走索引。
          3. 使用group by时，尽量使用select具体字段，防止数据超过mysql的内存buffer。
          
    * explain--常见的select type， type， extra
         - id:操作的顺序。数字越大越先执行；id相同则顺序执行。id列为null的就表是这是一个结果集
         - select_type：查询中每个 select 子句的类型。
            A：simple：不需要union/不包含子查询。简单select。可以有多个
            B：primary：需要union/有子查询，位于最外层的单位查询的select_type即为primary。且只有一个
            C：union：union连接的两个select查询，第一个查询是dervied派生表，除了第一个表外，第二个以后的表select_type都是union
            D：dependent union：与union一样，出现在union 或union all语句中，但是这个查询要受到外部查询的影响
            E：union result：包含union的结果集，在union和union all语句中,因为它不需要参与查询，所以id字段为null
            F：subquery：除了from字句中包含的子查询外，其他地方出现的子查询都可能是subquery
            G：dependent subquery：与dependent union类似，表示这个subquery的查询要受到外部表查询的影响
            H：derived：from字句中出现的子查询，也叫做派生表，其他数据库中可能叫做内联视图或嵌套select
         - table:通常表名(或者别名)
         - type:
            1.system：
                表中只有一行数据或者是空表，且只能用于myisam和memory表。如果是Innodb引擎表，type列在这个情况通常都是all或者index
            2.const：
               使用唯一索引或者主键，返回记录一定是1行记录的等值where条件时，通常type是const。
            3.eq_ref：
               连接几个表的查询中，驱动表只返回一行数据，且这行数据是第二个表的主键或者唯一索引，且必须为not null。
               唯一索引和主键是多列时，只有所有的列都用作比较时才会出现eq_ref。唯一性索引扫描，对于每个索引键，表中只有一条记录与之匹配。
               常见于主键或唯一索引扫描。eq_ref可以用于使用“=” 比较的带索引的列。比较值可以为常量或一个使用在该表前面所读取的表的列的表达式。
            4.ref：
               不像eq_ref那样要求连接顺序，也没有主键和唯一索引的要求，只要使用相等条件检索时就可能出现，
               常见与辅助索引的等值查找。或者多列主键、唯一索引中，使用第一个列之外的列作为等值查找也会出现，
               总之，返回数据不唯一的等值查找就可能出现。非唯一性索引扫描，返回匹配某个单独值的所有行。
               如果使用的键仅仅匹配少量行，该联接类型是不错的。ref可以用于使用=或<=>操作符的带索引的列。
            5.fulltext：全文索引检索
               优先级很高，若全文索引和普通索引同时存在时，mysql不管代价，优先选择使用全文索引
            6.ref_or_null：
               与ref方法类似，只是增加了null值的比较。实际用的不多。
            7.unique_subquery：
                用于where中的in形式子查询，子查询返回不重复值唯一值
            8.index_subquery：
                用于in形式子查询使用到了辅助索引或者in常数列表，子查询可能返回重复值，可以使用索引将子查询去重。
            9.range：索引范围扫描，
                常见于使用>,<,is null,between ,in ,like等运算符的查询中。
            10.index_merge：
                查询使用了两个以上的索引，最后取交集或者并集，常见and ，or的条件使用了不同的索引，官方排序这个在ref_or_null之后，但是实际上由于要读取多个索引，性能可能大部分时间都不如range
            11.index：索引全表扫描，把索引从头到尾扫一遍
                常见于使用索引列就可以处理不需要读取数据文件的查询、可以使用索引排序或者分组的查询。优点是避免了排序，因为索引就是已经排序好的
            12.all：
                全表扫描数据文件，然后再在server层进行过滤返回符合要求的记录。
         - possible_keys：可能会用到的索引。
         - key:实际用到的索引。
         - key_len:用到的索引键的平均长度，单位为字节。
         - ref:表示本行被操作的对象的参照对象，可能是一个常量用 const 表示，也可能是其他表的
         - key 指向的对象，比如说驱动表的连接列。
         - rows:估计每次需要扫描的行数。
         - filtered:rows*filtered/100 表示该步骤最后得到的行数(估计值)。
         -extra:重要的补充信息。
            1.using filesort：无法利用索引完成的排序操作称为“文件排序”,内部的一个快速排序,但是很低效。
                数据源必须是来源于一个Table，如果是两张表，就会先建立一个temporary，using temporary，然后排序
            2.using join buffer（block nested loop），using join buffer（batched key accss）：
                5.6.x之后的版本优化关联查询的BNL，BKA特性。减少内表的循环数量以及比较顺序地扫描查询。
            3.using temporary：使用了临时表存储中间结果。
                临时表可以是内存临时表和磁盘临时表，执行计划中看不出来，需要查看status变量，used_tmp_table，used_tmp_disk_table才能看出来。
                表示查询需要优化。
                MYSQL需要创建一个临时表来存储结果，这通常发生在对不同的列集进行ORDER BY上
            4.using where：
                表示存储引擎返回的记录并不是所有的都满足查询条件，需要在server层进行过滤。
                查询条件中分为限制条件和检查条件，5.6之前，存储引擎只能根据限制条件扫描数据并返回，然后server层根据检查条件进行过滤再返回真正符合查询的数据。5.6.x之后支持ICP特性，可以把检查条件也下推到存储引擎层，不符合检查条件和限制条件的数据，直接不读取，这样就大大减少了存储引擎扫描的记录数量。extra列显示using index condition
            5.using index：
                 出现这个说明mysql使用了覆盖索引，避免访问了表的数据行，效率不错！
    * profile
         用来分析sql性能的消耗分布情况，当用explain无法解决慢sql时，用profile
         - 操作
          mysql> show profiles;  查看sql语句
          mysql> show profile for query 7  排查具体sql；
    * processlist
         show processlist 显示用户正在运行的线程 (结果为：线程id， user， host， db， command， time， state)
    * 常见优化方向


### left join 和 inner join的区别
left join 是结果只有left表的信息
inner join 是两个表都有

### [order by原理](https://www.cnblogs.com/lamp01/p/10770172.html)
1. 如果排序字段在索引项上，因为索引本身就是排序的，索引直接返回就可以了
2. 排序字段不在索引项上(使用快排)：
    1. mysql为order by线程分配一段内存进行排序(Using filesort)叫sort buffer。
    2. ‘rowid排序’，排序内存小，影响排序效率时采用，可以一次排序更多的行,但是需要去回原表取数据；
       ‘全字段排序’，排序内存大时使用，直接在内存中返回查询结果；
    3. rowId排序第二次回表会按照rowid乱序去读取行记录，这些行记录在磁盘中的存储是分散的，是随机io，效率差
       也有因为rowId排序需要回表查而选用全字段排序，使用在内存中分块快排，再在磁盘上将各个块做归并。
        1.所有需要的列或ORDER BY的列只要是BLOB或者TEXT类型，则使用两次传输排序。
        2.所有需要的列和ORDER BY的列总大小超过maxlengthforsortdata字节，则使用两次传输排序
  
       
### mysql [死锁问题排查](https://www.cnblogs.com/boboshenqi/p/10710943.html)
1. 报警日志
     发现异常，尾随其后的还有报错相应的堆栈信息，指出了具体是哪个SQL语句发生了死锁
2. show engine innodb status(打开innodb lock monitor，可以查看普通事务的加锁情况);
     查询得到最近的一次死锁日志为(Latest detected Deadlock).
     从日志中可以看到只是简单的记录排它锁(X lock)，并非间隙锁(gap lock)。
     还能发现第一个事务阻塞在了更新会话的SQL语句中，经查询得到是更新消息为已读的SQL，第二个事务阻塞在了保存消息的SQL语句中
        
- innodb开启监控
- 开启标准监控
 set GLOBAL innodb_status_output=ON;
- 开启锁监控
 set GLOBAL innodb_status_output_locks=ON;
- 记录死锁日志
  set GLOBAL innodb_print_all_deadlocks=ON;
  
### [死锁日志分析](https://cloud.tencent.com/developer/article/1498086)
记录锁（LOCK_REC_NOT_GAP）: lock_mode X locks rec but not gap
间隙锁（LOCK_GAP）: lock_mode X locks gap before rec
Next-key 锁（LOCK_ORNIDARY）: lock_mode X
插入意向锁（LOCK_INSERT_INTENTION）: lock_mode X locks gap before rec insert intention

### 如果是MySQL引起的CPU消耗过大，你会如何优化？
- 谁在消耗cpu
   1. 用户+系统+IO等待+软硬中断+空闲 = cpu时间
   2. 系统，软硬中断改变较难
- 优化方向
   1. 用户空间CPU消耗，各种逻辑运算
       减少函数/排序/类型转化/逻辑IO访问…   
   2. 等待IO请求的完成
       1. index，优化索引，减少不必要的表扫描
            如增加索引，调整组合索引字段顺序，去除选择性很差的索引字段等等
       2. table，合理拆分，适度冗余
            如将很少使用的大字段拆分到独立表，非常频繁的小字段冗余到“引用表”
            
       3. SQL，调整SQL写法，充分利用现有索引，避免不必要的扫描，排序及其他操作
            如减少复杂join，减少order by，尽量union all，避免子查询等
       4. 数据类型，够用就好，减少不必要使用大字段
            如tinyint够用就别总是int，int够用也别老bigint，date够用也别总是timestamp


### mysql [性能调优](https://www.jianshu.com/p/19a8edf2fc47)
- 优化维度有四个：
  硬件、系统配置、数据库表结构、SQL及索引。
一般应急调优的思路：

- 针对突然的业务办理卡顿，无法进行正常的业务处理！需要立马解决的场景！
1.show processlist
2.explain sql; show index from table;
3.通过执行计划判断，索引问题（有没有、合不合理）或者语句本身问题
4.show status like '%lock%'; # 查询锁状态
5.kill SESSION_ID; # 杀掉有问题的session

- 系统配置方面
 1. vmstat 可以统计CPU、内存、swap、I/O操作、上下文切换、时钟切换等
       结果一共分为6部分：Pros、Memory、Swap、IO、System、CPU;
       1. Pros中，r是等待运行的进程数， b是处于非中断睡眠的进程数
       2. Memory中， swpd是虚拟内存，free是空闲内存，buff是用来做缓存的内存大小
       3. Swap中， si是从磁盘到内存的交换内存大小， so是内存到磁盘的交换内存大小
       4. IO中，bi是发送到块设备的块数， bo是从块设备接收的块数
       5. System中，in是每秒中断数， cs是上下问交换数
       6. Cpu中，us是用户时间，sy是系统时间，id是空闲时间
 2. iostat -d -k -x 5 （查看设备使用率（%util）和响应时间（await））
       1、tps：该设备每秒的传输次数。“一次传输”意思是“一次I/O请求”。多个逻辑请求可能会被合并为“一次I/O请求”。
       2、iops ：硬件出厂的时候，厂家定义的一个每秒最大的IO次数,"一次传输"请求的大小是未知的。
       3、kBread/s：每秒从设备（drive expressed）读取的数据量；
       4、KBwrtn/s：每秒向设备（drive expressed）写入的数据量；
       5、kBread：读取的总数据量；
       6、kBwrtn：写入的总数量数据量；这些单位都为Kilobytes。
      
问题一：cpu负载高，IO负载低
  1.内存不够; 2.磁盘性能差; 3.SQL语句问题; 4.tps过高:大量的小数据IO、大量的全表扫描; 5.IO出问题了（磁盘到临界了、raid设计不好、raid降级、锁、在单位时间内tps过高） 

问题二：IO负载高，cpu负载低
  1.大量小的IO写操作; 2.autocommit,产生大量小IO; 3.sql语句问题; 4.IO/PS,磁盘的一个定值，硬件出厂的时候，厂家定义的一个每秒最大的IO次数
  
问题三：IO和cpu负载都很高
   硬件不够了或sql存在问题
   
- mysql进程导致的负载高处理办法：
1.常见的就是mysql慢查询导致，可以在mysql慢查询日志找到相关sql语句，这需要对sql进行优化
2.还可以进入mysql，用show full processlist\G;查看那个mysql进程执行时间比较久的慢查询。如果是内部后台使用的语句，可以先kill掉，优化后再执行。
3.mysql读写太频繁，如果是读写频繁可以在%wa等待输入输出看的出来占用cpu百分比很大。也可以通过命令iostat查看系统读写情况。
   
- 监控mysql
1. 监控cpu使用率
2. 监控mysql线程数，
3. 监控慢查询
4. 监控主从延时情况。
5. 监控insert，update， delete
   
### 数据库优化
- SQL优化方向：执行计划、索引、SQL改写
- 架构优化方向：高可用架构、高性能架构、分库分表

- 数据库参数优化
1.实例整体
   thread_concurrency      # 并发线程数量个数
   sort_buffer_size        # 排序缓存
   read_buffer_size        # 顺序读取缓存
   read_rnd_buffer_size    # 随机读取缓存
   key_buffer_size          # 索引缓存
   thread_cache_size        # (1G—>8, 2G—>16, 3G—>32, >3G—>64)
2.连接层（设置合理的连接客户和连接方式）
   max_connections          # 最大连接数，看交易笔数设置
   max_connect_errors        # 最大错误连接数，能大则大
   connect_timeout          # 连接超时 
   max_user_connections      # 最大用户连接数
   skip-name-resolve        # 跳过域名解析 
   wait_timeout              # 等待超时
   back_log                  # 可以在堆栈中的连接数量
3.存储引擎层（innodb基础优化参数）
   default-storage-engine
   innodb_buffer_pool_size # 没有固定大小，50%测试值，看看情况再微调。但是尽量设置不要超过物理内存70%
   innodb_file_per_table=(1,0)
   innodb_flush_log_at_trx_commit=(0,1,2) # 1是最安全的，0是性能最高，2折中
   binlog_sync
   Innodb_flush_method=(O_DIRECT, fdatasync)
   innodb_log_buffer_size # 100M以下
   innodb_log_file_size          # 100M 以下
   innodb_log_files_in_group    # 5个成员以下,一般2-3个够用（iblogfile0-N）
   innodb_max_dirty_pages_pct  # 达到百分之75的时候刷写 内存脏页到磁盘。
   log_bin
   max_binlog_cache_size # 可以不设置
   max_binlog_size              # 可以不设置
   innodb_additional_mem_pool_size    #小于2G内存的机器，推荐值是20M。32G内存以上100M

### 数据库连接池
- 常用的连接吃
    1. c3p0/dbcp(老旧被抛弃)
    2. druid(功能全)
    3. HikariCP(小巧性能好)
- 主要参数
    最小连接数，最大连接数， 最大空闲时间， 超时重试连接次数
    
### 字符集编码 https://www.jianshu.com/p/96ee5b2adef3
1. MySQL中不同层次有不同的字符集编码格式,主要有四个层次:服务器,数据库,表和列
2. COLLATION校对规则,校对规则不指定就是使用默认的，比如utf8字符集对应的默认校对规则就是utf8_general_ci。
3. 校对规则后缀如_cs,_ci,_bin分别表示是大小写相关/大小写无关/以字符串编码的二进制值来比较大小
4. 如果比较的两个字符集不同，则mysql在比较前会先将其转换到同一个字符集再比较
  
### [ddl online](../picture/ddl_online.jpg)
ALTER TABLE时ALGORITHM可以指定的几种方式(执行DDL操作时，ALGORITHM选项可以不指定，这时候MySQL按照INSTANT、INPLACE、COPY的顺序自动选择合适的模式)
- COPY模式
      指DDL时，会生成（临时）新表，将原表数据逐行拷贝到新表中，在此期间会阻塞DML
- INPLACE模式
      无需拷贝全表数据到新表，但可能还是需要IN-PLACE方式（原地，无需生成新的临时表）重建整表。
      这种情况下，在DDL的初始准备和最后结束两个阶段时通常需要加排他MDL锁（metadata lock，元数据锁），除此外，DDL期间不会阻塞DML
- INSTANT模式
     只需修改数据字典中的元数据，无需拷贝数据也无需重建整表，同样，也无需加排他MDL锁，原表数据也不受影响。
     整个DDL过程几乎是瞬间完成的，也不会阻塞DML。这个新特性是8.0.12引入的            

[mysql 官方文档](https://dev.mysql.com/doc/refman/5.7/en/innodb-online-ddl-operations.html#online-ddl-table-operations)
1.索引相关