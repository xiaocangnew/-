### 线程安全的容器：
1. 同步容器类：
     1.synchronized修饰； 2.HashTable
2. 并发容器：
     1. ConcurrentHashMap:分段
     2. CopyOnWriteArrayList：写时复制
     3. CopyOnWriteArraySet：写时复制
3. Sorted容器：
     1. ConcurrentSkipListMap：是TreeMap的线程安全版本
     2. ConcurrentSkipListSet：是TreeSet的线程安全版本

4. Queue（java.util.concurrent.BlockingQueue 接口代表了线程安全的队列, 使用了ReentrantLock）
     1. ConcurrentLinkedQueue：是使用非阻塞的方式实现的基于链接节点的无界的线程安全队列，性能非常好。
     2. ArrayBlockingQueue：基于数组的有界阻塞队列
     3. LinkedBlockingQueue：基于链表的有界阻塞队列。
     4. PriorityBlockingQueue：支持优先级的无界阻塞队列，即该阻塞队列中的元素可自动排序。默认情况下，元素采取自然升序排列
     5. DelayQueue：一种延时获取元素的无界阻塞队列。
     6. SynchronousQueue：不存储元素的阻塞队列。每个put操作必须等待一个take操作，否则不能继续添加元素。内部其实没有任何一个元素，容量是0



### concurrentHashMap  jdk1.7 <-> jdk1.8
1. 结构上的变化:
     1.取消原先的Segment设计，取而代之的是使用与HashMap同样的数据结构，但其内部仍然有Segment定义，但仅仅是为了保证序列化时的兼容性而已，不再有任何结构上的用处
     2.引入了懒加载机制。会等到第一次put方法调用时才初始化Node[]
2. 线程安全方面的变化:
     1.锁粒度更细:
         由原来的锁Segment一片区域到锁桶的头结点,头结点下边的节点都不会加入同步队列里，
     2.由原先的ReentrantLock替换为Sychronized+CAS
        - 2.1. 性能上差不多(当前版本synchronized不断优化后)
        - 2.2. 使用Sychronized可以节省大量内存空间
                 原来ReentrantLock下的segment都得加入同步队列，都得继承AQS下的Node，
                 而synchronized只是锁住头结点，头结点下边的节点都不会加入同步队列里，所以节省了空间


### 底层数据结构：
- jdk1.7
    - 其本质是一个segment[]数组,分段锁就是对segment进行，每个segment维护一个HashEntry<K,V>[]数组，扩容时只能扩单个segment下的容，整体不能扩容，在new时就订好了；
    - 这个链表是final类型不可更改。1.新增数据只能加到链表头。2.删除时只能复制删除节点前面的部分，并使得next指向删除节点的下一个节点。
- jdk1.8
    与hashMap一样

### 初始化数据结构时的线程安全
- 在jdk1.7中
1.新建时就初始化；
- 在JDK1.8中
1.初始化ConcurrentHashMap的时候这个Node[]数组是还未初始化的，会等到第一次put方法调用时才初始化：
2.如果多个线程同时调用initTable初始化Node数组会有并发问题, 初始化数组使用了乐观锁CAS操作来决定到底是哪个线程有资格进行初始化，其他线程均只能等待。
    - 用到的并发技巧：
      1.volatile变量（sizeCtl）：它是一个标记位，用来告诉其他线程这个坑位有没有人在，其线程间的可见性由volatile保证。
      2.CAS操作：CAS操作保证了设置sizeCtl标记位的原子性，保证了只有一个线程能设置成功

### put操作的线程安全
- jdk1.8
   减小锁粒度：将Node链表的头节点作为锁，若在默认大小16情况下，将有16把锁，大大减小了锁竞争，
   将串行的部分最大化缩小，在理想情况下线程的put操作都为并行操作。同时直接synchronized锁住头节点，保证了线程安全

### get操作
- jdk1.7 不需要进行加锁
   通过Unsafe.getObjectVolatile()方法提供的原子读语义，来获得Segment以及对应的链表，然后对链表遍历判断是否存在key相同的节点以及获得该节点的value。
   由于遍历过程中其他线程可能对链表结构做了调整(调整时，由于final,所以修改会复制原来的数组，同时并行两个数组)，
   因此get和containsKey返回的可能是过时的数据，这一点是ConcurrentHashMap在弱一致性上的体现。如果要求强一致性，那么必须整个map加锁
- jdk1.8
   对于get操作，其实没有线程安全的问题，只有可见性的问题，只需要确保get的数据是线程之间可见的即可：
   使用了tabAt方法Unsafe类volatile的方式去获取Node数组中的Node，保证获得到的Node是最新的

### 扩容时的线程安全
- [扩容操作](https://blog.csdn.net/ZOKEKAI/article/details/90051567)
    ConcurrentHashMap支持多线程并发扩容，在扩容过程中同时支持get查数据，若有线程put数据，还会帮助一起扩容，这种无阻塞算法，将并行最大化的设计
- 基础概念
   - 变量:sizeCtl
      1)map未初始化时记录的是初始容量大小
      2)在初始化过程中将sizeCtl= -1,其他线程发现该值为 -1 时会让出CPU资源以便初始化操作尽快完成
      3)正常后sizeCtl 用于记录触发集合扩容的极限值
      4)在扩容过程中记录当前扩容的并发线程数
   - 变量transferIndex
       数组上hash桶的迁移工作已经'分配到'的位置(从右到左分配)
   - 线程内迁移
      1)stride：当前线程需要迁移hash桶的个数
      2)i:当前线程迁移任务开始下标； bond：结束下标， 从右到左迁移；
      3）每个线程承担不小于 16 个槽中的元素的扩容，然后从右向左划分16个槽给当前线程去迁移，
      每当开始迁移一个槽中的元素的时候，线程会锁住当前槽中列表的头元素
   - forwardingNode
      1）标识该hash桶的数据迁移已经完成
      2）转发，遇到get操作时转发到扩容后的新数组上
   - 迁移过程中的ln（低位Node）、hn（高位Node）
      1)在put值的时候，首先会计算hash值，再散列到指定的Node数组下标中(1.得到key的hashCode; 2.使用(n - 1) & hash 运算，定位Node数组中下标值)
      2)低位链表放入原下标处，而高位链表则需要加上原Node数组长度

- 常见问题
   - 扩容如何保证线程安全
   - 触发扩容条件：
      - 在put值时，发现Node为占位Node（fwd）时，会协助扩容
      - 在新增节点后，检测到链表长度大于8时，同时数组长度小于64。
      - 超过总容量后扩容
   - 扩容时put
      - 插入的位置扩容线程还未迁移到，直接插入
      - 只要，当迁移到该插入的位置时，就会阻塞等待插入操作完成再继续迁移
   - 扩容时get
      - 扩容过程期间形成的hn和ln链是使用的复制引用的方式，原来 hash 桶上的链表并没有受到影响
      - 从迁移开始到迁移结束这段时间都是可以正常访问原数组hash桶上面的链表
      - 迁移结束后放置上fwd，往后的访问请求就直接转发到扩容后的数组去了
   - 扩容完成后为什么要再检查一遍
      - 因为扩容是分段进行的，当前线程扩容完，其他线程可能还没有扩容完成，需要再检查一次，而且会帮忙一起扩容

### size()的线程安全
- 基于整个ConcurrentHashMap操作,原理：
    - 首先不加锁循环执行以下操作：循环所有的Segment(通过Unsafe的getObjectVolatile()以保证原子读语义），获得对应的值以及所有Segment的modcount之和。
      如果连续两次所有Segment的modcount和相等，则过程中没有发生其他线程修改ConcurrentHashMap的情况，返回获得的值。
      当循环次数超过预定义的值时，这时需要对所有的Segment依次进行加锁，获取返回值后再依次解锁。值得注意的是，加锁过程中要强制创建所有的Segment，否则容易出现其他线程创建Segment并进行put，remove等操作。

### jdk1.7 有并发度概念，  1.8 没有
- 就是ConcurrentHashMap中的分段锁个数，即Segment[]的数组长度。
   ConcurrentHashMap默认的并发度为16。当用户设置并发度时，ConcurrentHashMap会使用大于等于该值的最小2幂指数作为实际并发度（假如用户设置并发度为17，实际并发度则为32）。
- 并发度设置的过小，会带来严重的锁竞争问题；
- 并发度设置的过大，原本位于同一个Segment内的访问会扩散到不同的Segment中，CPU cache命中率会下降，从而引起程序性能下降。

### putIfAbent()
- ConcurrentHashMap本身是一个线程安全的容器，putIfAbent()也没有问题。
- 但是其不适合保存创建计算机资源的场景。因为计算机资源诸如：线程池、IO等都是有限的，如果还不涉及到自动回收的话就更宝贵了。
putIfAbent()每次都会创建成功，但不一定被存放到Map中，就不会被使用到，就造成了浪费。


### HashMap 的线程不安全
- 扩容在jdk1.7中会导致死循环
    扩容过程中使用头插法将oldTable中的单链表中的节点插入到newTable的单链表中(put时使用的也是头插法，最近经常使用的放在最上面)
    所以newTable中的单链表会倒置oldTable中的单链表。
    那么在多个线程同时扩容的情况下就可能导致扩容后的HashMap中存在一个有环的单链表，
   从而导致后续执行get操作的时候，会触发死循环，引起CPU的100%问题。
- 在jdk1.8 时可能发生put覆盖；
   1. 正好hash到同一个位置上，正常会产生链表，但是多线程时直接丢失。
   2. 在扩容时使用尾插法， 不会存在死锁问题；

- [jdk1.7头插法进行扩容实现死锁](https://my.oschina.net/u/4305379/blog/4529330)
   两个线程都进行扩容， 一个线程扩容完毕后，另一个线程再从中断处开始扩容，会形成环；
void transfer(Entry[] newTable, boolean rehash) {
        int newCapacity = newTable.length;
        for (Entry<K,V> e : table) {
            while(null != e) {
            	//1， 获取旧表的下一个元素
                Entry<K,V> next = e.next; //提前保存e的下一个节点，下面e.next要更改；
                if (rehash) {
                    e.hash = null == e.key ? 0 : hash(e.key);
                }
                int i = indexFor(e.hash, newCapacity);
                e.next = newTable[i];  // e的下一个节点为newTable[i]， e为新的头节点；
                newTable[i] = e;   //把新的头节点放到数组位置上；
                e = next;     //循环
            }
        }
    }


### hashMap的resize()
- 1. 什么时候扩容
       当前元素个数 > 数组容量 * loadFactor
- 2. 扩容后容量翻倍，长度为什么是2的n次方
       1.当数组长度为2的n次幂的时候，不同的key算得得index相同的几率较小，那么数据在数组上分布就比较均匀，也就是说碰撞的几率小，
       相对的，查询的时候就不用遍历某个位置上的链表，这样查询效率也就较高了
       2.空间浪费，如果不是16，而是15， 那么 e&(n-1)时，15-1的二进制位上有0出现，导致有几个位置永远不能放元素。
- 3. 扩容的时机
       初始化后首次插入数据时，先发生resize扩容再插入数据，
       之后每当插入的数据时，是先插入数据再resize。
- 4. 元素迁移
    - jdk1.7
      1. 在准备好新的数组后，map会遍历数组的每个“桶”，然后遍历桶中的每个Entity，重新计算其hash值（也有可能不计算），
      2. 找到新数组中的对应位置，以头插法插入新的链表， 链表会逆序。(多线程可能死循环)
    - jdk1.8(性能提升很大)
       1. 经过rehash之后，元素的位置要么是在原位置，要么是在(原位置+oldCap)位置。。
          因此，在扩容时，不需要重新计算元素的hash了，只需要hash&(oldCap-1)，判断最高位是1还是0就好了，0不变，1相加
       2. JDK8在迁移元素时是正序的，不会出现链表转置的发生。
- 5. 在resize过程中put操作，结果未知，多线程不安全



### CopyOnWriteArrayList
1. 为什么读写之间不用互斥?
    关键就在于添加值的操作并不是直接在原有数组中完成，而是使用原有数组复制一个新的数组，然后将值插入到新的数组中，最后使用新数组替换旧数组，这样插入就完成了。
2. 数组定义采用volatile修饰，
   保证内存可见性，读取线程可以马上知道这个修改