### codis VS kedis

1. 接入方式方面
路由信息：Codis使用ZK管理集群信息，路由信息属于集中式调度，Kedis使用Redis-cluster管理集群信息，集群信息完全是分布式。
Codis的接入方式：除了proxy方式访问集群外；Codis的Java客户端有Jodis，可以使用ZK方式接入集群，但是问题是，当机器死机时，可能会面临ZK不摘除故障机器导致请求量按照比例丢失风险。
Kedis的接入方式：Kedis是完全通过Proxy方式访问集群；（Redis-cluster理论上也可以访问，但是不对外暴露）
Kedis和Codis统一对外暴露VIP地址，在接入方式上对用户没有区别。
2.结构方面
Codis结构
Codis集群属于强依赖zk，由ZK来管理所有的集群信息。Proxy上缓存了集群的路由信息，每当有请求时，通过CRC32获取该key所属的Slot（共1024个），根据路由信息确定该Slot所属的Group，然后转发到Group所属的Master。
Codis的最小规模为两台机器，独立部署时每台机器部署16个实例，8Master，8Slave。每个Master默认6G内存。使用机器型号M10、C1601每台机器可提供50G可用容量（50G热备份）。当申请小于50G时，就会进行混布。
Codis的Proxy是多线程。
在机器出现单台故障时，由Proxy内部的实例探活协程检查实例处于offline状态，更新ZK信息来通知其他所有Proxy进行缓存路由信息更新，再将Slave提升为Master。故障时死机触发的主从切换为15-18s。
Kedis结构
Kedis使用的是Redis-cluster来管理集群。Proxy上会缓存集群的路由信息，但是不保证路由信息的一致性，理论上最终是一致的。Redis-cluster的slot一共有16384个，Proxy根据请求的Key计算请求所属的slot，然后根据缓存的路由信息
转发到所属的node，如果转发收到moved node信息，则会重新更新缓存路由。
Kedis的最小规模为3台机器。每台机器部署同样16个实例。
Kedis的proxy是单进程单线程。
在机器出现单台故障时，由Redis-cluster 选举Slave成为Master，同时更新Proxy路由信息。
Kedis对外统一提供的是VIP，可以由VIP提供容灾和负载均衡，单台Proxy故障时，VIP18-21S摘除故障Proxy。
3. 不支持的命令方面
Codis和Kedis对外的不支持命令是一致的，Codis/Kedis不支持哪些命令。
另外Kedis在lua的参数校验上会更加严格。Codis在执行lua的时候，只将lua转发到第一个key所属的redis实例，其他参数key内容不关心。Kedis会校验lua执行的所有key参数，如果多个key不在同一个实例（分片slot），则会写入不成功。
4. 稳定性方面
Codis: Codis的所有信息在zk中，对zk强依赖，zk异常可能会导致proxy异常重启；高可用HA是在proxy的探活协程和zk检查协程完成，单个proxy可能会误判redis故障，导致不必要的选举。
Kedis：Kedis的proxy对路由信息不强依赖，Kproxy通过命令返回结果，周期检查更新自身路由信息；Kedis的高可用，通过分布式节点广播消息选举切换，切换准确性更高。
Codis和Kedis的横向扩容，迁移数据都支持逐个key的顺序迁移，均会受到大key问题阻塞服务，kedis的平均迁移速度更快，平均是codis的两倍。此外Kedis支持急速扩容方式，可以解决大key迁移问题，并且迁移速度会有质的飞越。
5. 多活一致性
Codis集群双活(滴滴目前已经不在维护)
Codis的双活主要方式是在两个集群的Proxy层，开启一组双写端口， 每次从业务层来的写操作都会同步到对端集群。
该方式针对网络抖动丢包，机器故障，proxy重启等操作都会有数据不能传递到对端集群的可能性，所以不能保证数据的一致性，最终一致性也不能保证。
Kedis集群多活
Kedis集群多活相比Codis的多活有一定的提升，但是仍然没有解决数据一致性问题。
Kedis多活依赖Mq，是将客户端写入Redis的数据生产给mq，然后在对端集群的proxy层消费mq的数据。mq数据本地持久化，所以只要mq数据不丢失，那么对于非增量数据（string）就能保证一致性。
跨机房网络时延，增量数据一致性无法保证。另外针对两边同时操作同一个key，由于网络时延可能导致的数据最终一致性仍然可能不一致。

6. 性能方面
Proxy：Kedis使用C语言编写，单协程，更轻量。无Codis的go gc现象。Codis的默认绑cores16个，kedis单core。
Redis：Codis使用的是2.8版本的redis：Kedis使用的是3.2版本的redis；Codis的redis是经过特殊改造的，会存放较多的proxy和slave相关信息，内存使用量单实例会多占用108M数据。
此外3.2版本有这些主要提升。 migrate命令迁移更快，平均是Codis的2倍；增加GEO数据结构；sds，incr，lua脚本性能大幅度提升。
其他可以参考：Codis升级



kedis
 kedis是公司自主研发的基于redis-cluster的缓存集群服务。主要包含两部分，1、redis-cluster ，在开源的3.2.8版本基础上，进行了修改和优化，主要负责用户数据的存储。2、kproxy，自研制，主要用于客户端链接建立，流量转发。

   kproxy主要有三部分组成：
          2.1 建立链接模块。与客户端和redis-clsuster建立链接。
          2.2 命令处理模块。区分单次操作命令和多次操作命令（Mget/Mset）。
          2.3 路由模块。维护redis-cluster的nodes路由信息。
          客户端通过与Kproxy建立链接，Kproxy根据客户端的请求，对key进行crc16%16384，计算出该key所属的redis node。再将相关的请求转发到对应的redis node。如果是多命令集合，则会维护链表记录相关操作，对应答信息汇总后才统一返回结果。Kproxy在启动时会加载配置中的nodes信息，
          如果出现接收到redis-cluster的moved结果，则会重新获取redis-cluster nodes信息。  
         
CAP选择
缓存服务本身对数据准确性的要求没有那么严格，而且本身多活方案就是为了保证可用性。
因此CAP中，选择AP，某些场景下会为保证可用性舍弃部分一致性。