### 引用  强> 软> 弱  >虚
- 软引用
   在jvm内存不足时才会回收
- 弱引用
   在jvm进行垃圾回收时就会回收
   
SoftReference<String> softRef=new SoftReference<String>(str);软引用可用来实现内存敏感的高速缓存。 
WeakReference<String> abcWeakRef = new WeakReference<String>(str);

### 常用的命令
- jstat 实时显示jvm进程中的各种情况
     命令格式：
        jstat -gcutil pid timesInterval showCounts 
        显示gc相关信息百分比(包括堆区各个分代的容量，使用大小，gc次数和gc时间等)
        
- jstack 线程快照，显示线程正在执行的方法,可定位长时间停顿的原因，或线程死锁，cpu过高等。
     命令格式:jstack [option] pid (-F:force, -l:lock信息)
     
- jmap 显示堆和永久代的详细信息
     - 常用命令
       jmap -heap pid  显示堆信息
       jmap -dump:live,format=b,file=m.hprof PID    下载文件
       jmap -histo:live pid | head -n 10 统计对象大小
       
- 导出异常内存文件 dump
1. 内存溢出时让其自动生成： 配置jvm参数-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/home/biapp/m.hprof
2. 在没有hprof文件下强制导出: jmap -dump:live,format=b,file=m.hprof PID

### 一次oom线上问题解决
- 前提： jar包启动时配置了参数 XX:+HeapDumpOnOutOfMemoryError
0. 根据关键词 “java.lang.OutOfMemoryError”进行搜索日志(根据提示看代码，如果找到最好，否则下一步)
1. 使用MAT打开拿到的hprof文件进行分析。
2. 打开Histogram看看占用内存最大的是什么对象：
    2.1. 在最大对象上右键：merge shortest path to gcroots --> with all references
    2.2. 点开对象的内容是什么(有可能是内容导致的)
    2.3. (名词解释： shallow heap 是对象本身大小， retained heap为对象和他的引用总共大小)
5. 分析业务代码
6. [网页来源](https://www.cnblogs.com/lovecindywang/p/10800593.html)
修改springboot配置
  server:
   tomcat:
    max-http-header-size: 65536
7. [url异常](https://blog.csdn.net/gallenzhang/article/details/98520496)

### 一次测试环境 cpu 100% 问题排查 
- 某个业务代码导致(代码没有严格review导致某处while死循环)
1. 使用top命令查看cpu高的程序  
2. 使用 top -H -p PID 查看程序中cpu高的线程
3. 线程id进制转换 printf “%x\n“ ppid
4. jstack -l ppid

### 频繁full gc导致
0. 通过命令查看cpu占用(和业务代码导致cpu过高一致)
1. 每个线程资源占用分布平均，查看当前进程的GC问题
2. 观看每秒一次的GC状态 #jstat -gcutil 10010 1000 10#
3. S0,S1区，E区这2个区一般不会有什么问题，除非配置极端不合理
   O区(老年代)资源占用率过高导致FGC，处理方式是进行资源调整或者检查程序是否有什么异常
   M区(永久代)资源占用率过高，
    查看是否有过多的class加载#jstat -class 10010# 或者是否有大的对象无法GC#jmap -histo 10010#
    
``````
// 1. 如果textList为空，则iterator陷入死循环。（业务场景是根据过滤人数中的没有取消过订单的人）
while(iterator.hasNext()){
  for(String text : textList){  
    if(iterator.next().equals("a)){
      iterator.remove();
    }
  }
}

// 2. static使用导致的内存泄露

// 3. map导致内存溢出
 map.put(key, value)。 其中，key为一个类，但是没有使用equasl方法，put太多会溢出。

``````

### jvm 调优 --主要的目的是减少GC的频率和Full GC的次数。




### [线上问题排查](https://blog.csdn.net/weixin_34162228/article/details/93019589)
0. 问题描述
    1. 线上的服务突然变慢(通常是gc问题)
    2. 突然out-of-memeory
    3. cpu利用率变高
    4. 磁盘io占用过高(大量读写文件)
    5. 网络延迟变长
1. 业务相关
    1. 查看日志中Error错误，统计error错误数量。
    2. PV量过高
         (日志/监控)分析服务请求量，耗时，成功率和失败率
    3. 服务调用耗时异常
         耗时过长的服务调用如果没有熔断等机制，很容易导致应用性能下降或服务不可用，服务不可用很容易导致雪崩。
    4. 死锁，多线程并发
    5. 异常安全攻击扫描等。
2. 数据库相关
    一条sql没写好导致慢查询，可能会导致整个应用挂起
    此时需要查看数据库连接请求、是否连接数过大，是否出现死锁、查看数据库慢日志定位具体SQL
3. JVM相关
      3.1 OOM相关
           发生OOM问题一般服务都会crash，业务日志会有OutOfMemoryError
      3.2 死锁
           死锁原因是两个或者多个线程相互等待资源。现象通常是出现线程hung住。
           更严重会出现线程数暴涨，系统出现api alive报警等。查看死锁最好的方法就是分析当时的线程栈。
            jstack -l pid (打印进程的栈信息，长列表打印，关于锁的附加信息，同时会使jvm停顿很久)
      3.3 线程block、线程数暴涨
           1. 线程block问题通常是等待io、等待网络、等待监视器锁等造成，
               可能会导致请求超时、造成造成线程数暴涨导致系统502等。
           2. 使用命令：
               jstack -l pid |wc -l          
               jstack -l pid |grep "BLOCKED"|wc -l           
               jstack -l pid |grep "Waiting on condition"|wc -l
      3.4 [gc时间过长](https://blog.csdn.net/goldenfish1919/article/details/97155089)
             使用jstat命令查看gc时间，如果过长，需要调优
             1. 对象创建的速度过高，随之而来的就是GC频率也会变快，然后会导致GC的停顿时间变长。
                 把GC日志上传到gceasy.io，这个工具会告诉你对象的创建速度
             2. Young区过小
             3. 选择合适的GC算法, 使用g1垃圾回收器，23点都没有了
             4. 进程被交换（Swap）出内存, 也会导致gc时间变长
             5. GC线程数过少
             6. IO负载重
4. Server本身问题
     1. CPU占用率过高,CPU上下文切换频率次数较高
          1. 通过top命令查看，
               loadAvge < cpu*0.7
               wa 表示io等待时间占比； 
          2. vmstat查看：
               cs (context switch) 每秒的上下文切换次数
               in (interrupt) 每秒的中断次数
               r (Runing or Runnable) 就绪队列的长度，也就是正在运行和等待CPU的进程数。
               b (Blocked) 不可中断睡眠状态的进程数
          3. pidstat查看进程的上下文交换
                cswch 自愿上下文切换，指的是进程无法获得所需的资源导致的上下文切换，比如I/O不足，内存不足
                nvcswch 非自愿上下文切换，指的是 进程由于时间片已到等原因，被系统强制调度，进而发生上下文切换。比如大量进程在争抢CPU
          4. 一般上下文切换在数百到一万之内。上下文切换超过1万，很可能遇到性能问题。
     2. 磁盘满了, 磁盘I/O过于频繁
          通过df查看磁盘空间， iostat查看磁盘io情况
     3. 网络流量异常 (连接数过多, 网络延迟变长)
          通过netstat命令查看网络流量 (查看协议，ip:port等)
          [问题排查](../http-socket/tcp问题记录.md)
     4. 系统可用内存长期处于较低值 (导致 oom killer) 等等。   
          通过free命令查看内存空间，vmstat查看内存情况
     
 [](https://blog.csdn.net/GitChat/article/details/79019454)