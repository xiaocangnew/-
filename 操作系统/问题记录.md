### 用户态和内核态
- 内核态：1.可以访问内存的所有'数据'，包括外围设备，例如硬盘，网卡. 
         2.'cpu'也可以将自己从一个程序切换到另一个程序。
- 用户态：1. 只能受限的访问内存，且不允许访问外围设备. 
        2. 占用cpu的能力被剥夺，cpu资源可以被其他程序获取。
 
- 为什么要有用户态和内核态？
    由于需要限制不同的程序之间的'访问能力', 防止他们获取别的程序的内存数据, 或者获取外围设备的数据, 并发送到网络,
     CPU划分出两个权限等级 -- 用户态和内核态。
     
- 用户态切换到内核态的3种方式
   1. 系统调用.用户态进程通过系统调用申请使用操作系统提供的服务程序完成工作
   2. 异常. 运行在用户态下的程序时，发生了一些没有预知的异常，这时会触发由当前运行进程切换到处理此异常的内核相关进程中，也就是切换到了内核态，如缺页异常。
   3. 外围设备的中断。
       当外围设备完成用户请求的操作后，会向CPU发出相应的中断信号，这时CPU会暂停执行下一条即将要执行的指令而转到
       与中断信号对应的处理程序去执行，如果前面执行的指令时用户态下的程序，那么转换的过程自然就会是由用户态到内核态的切换。如硬盘读写操作完成，
       
### 线程和进程的区别
1. 根本区别：
     进程是资源分配最小单位，
     线程是程序执行的最小单位。
2. 地址空间：
    进程有自己独立的地址空间，每启动一个进程，系统都会为其分配地址空间，建立数据表来维护代码段、堆栈段和数据段；
    线程没有独立的地址空间，同一进程的线程共享本进程的地址空间。
3. 资源拥有：
     进程之间的资源是独立的；
     同一进程内的线程共享本进程的资源。
4. 执行过程：
     每个独立的进程程有一个程序运行的入口、顺序执行序列和程序入口。
     线程不能独立执行，必须依存在应用程序中，由应用程序提供多个线程执行控制。
### 协程
- 协程是比线程更轻量级的处理单位，一个线程可以有多个协程
- 一个线程内的协程是串行处理的，即使使用多核处理器。
- 协程不是被操作系统内核所管理的，而是完全由程序所控制，也就是在用户态执行

- 协程的好处：
1.跨平台，跨体系架构
2.无需线程上下文切换的开销
3.无需原子操作锁定及同步的开销


### 同步IO: sync、fsync与fdatasync
1. 传统的UNIX实现在内核中设有缓冲区高速缓存或页面高速缓存，大多数磁盘I/O都通过缓冲进行。
2. 当将数据写入文件时, 使用了延时写：内核通常先将该数据复制到其中一个缓冲区中，如果该缓冲区尚未写满，
   则并不将其排入输出队列，而是等待其写满或者当内核需要重用该缓冲区以便存放其他磁盘块数据时，
   再将该缓冲排入输出队列，然后待其到达队首时，才进行实际的I/O操作。
3. 延迟写减少了磁盘读写次数，但是却降低了文件内容的更新速度，
 使得欲写到文件中的数据在一段时间内并没有写到磁盘上。当系统发生故障时，这种延迟可能造成文件更新内容的丢失。
4. UNIX系统提供了sync、fsync和fdatasync三个函数来保证实时写。
    4.1 sync，实时写，但是不等待结果
    4.2 fsync， 阻塞实时写，得到结果后才返回；
    4.3 fdatasync， 同4.2一致，只是只写数据部分，性能更好。
    
### 磁盘阵列RAID
1. 目的： 提高单磁盘导致的io性能瓶颈。
2. 方式： 多个磁盘使用条带化存储，对外模拟成单磁盘；
3. 根据可靠性分为：
    RAID0 没有冗余，数据不可靠，但性能最高
    RAID1 镜像冗余，成本最高
    并行访问： RAID2和RAID3， 使用了N+logN的方式冗余
    独立访问： RAID4-6， 使用N+1冗余
               
### 冯·诺依曼体系结构
- 存储程序原理：把程序本身当作数据来对待，程序和该程序处理的数据用同样的方式储存。
- 要点是：计算机的数制采用二进制；计算机应该按照程序顺序执行
- 主要由：运算器、控制器、存储器、输入设备、输出设备

### OLAP VS OLTP
OLTP是传统的关系型数据库的主要应用，主要是基本的du、日常的事务处理，例如银行交易。
OLAP是数据仓库系统的主dao要应用，支持复杂的分析操作，侧重决策支持，并且提供直观易懂的查询结果。

### 负载与cpu的区别
- CPU使用率：显示的是实时占用的CPU百分比
- load average：系统平均负载,是CPU的Load,显示的是一段时间内正在使用和等待使用CPU的平均任务数
   0. CPU负载是基于内核数来计算的, 有多少内核，即有多少负载，即4核cpu， 负载为4时，正好;
   1. CPU使用率高，并不意味着负载就一定大。
         如果我有一个程序它需要一直使用CPU的运算功能，那么此时CPU的使用率可能达到100%，但是CPU的工作负载则是趋近于“1”，因为CPU仅负责一个工作嘛！
         如果同时执行这样的程序两个呢？CPU的使用率还是100%，但是工作负载则变成2了。所以也就是说，当CPU的工作负载越大，代表CPU必须要在不同的工作之间进行频繁的工作切换。
   2. 0.00, 0.00, 0.00这三个值分别代表 1分钟、5分钟、15分钟前到现在的平均值
         如果这三个值从左到右越来越高代表服务器平均负载在下降，相反代表服务器的负载在上升


### 零拷贝技术
- 基础知识点：
   - 户态和内核态
      处于用户态执行时，能访问的内存空间和对象受到限制，占有的处理器是可被抢占的
      处于内核态执行时，能访问所有的内存空间和对象，   占有的处理器是不允许被抢占的
   - DMA（Direct Memory Access）直接内存访问
      DMA允许外设组件将I/O数据直接传送到主存储器中；并且传输不需要CPU的参与，来释放CPU时间分片资源。

- 优化线
   - (用户在网上浏览信息)为例收到请求后的数据流(4次copy)：
      磁盘文件--(DMA copy)--> 内核态ReadBuffer --(cpu copy)-->用户态AppBuffer --(cpu copy)-->内核态socketBuffer--(DMA copy)--> 网络上NicBuffer
   - 痛点：
      1. 两次cpu copy占用cpu时间
      2. 需要从内核态和用户态切换
   - Linux2.1 内核优化：
        跳过AppBuffer步骤(mmap技 术,实现数据共享)，直接从ReadBuffer--(cpu copy)-->socketBuffer
   - Linux2.4 内核优化:
        操作系统提供scatter/gather这种DMA的方式，来从内核空间缓冲区中将数据直接读取到协议引擎,消除了最后一次cpu copy
        socketBuffer不再copy信息，里面只有数据的位置和长度的信息的描述符，
   n
- 注意：零拷贝其实是根据内核状态划分的，
   1. 数据在用户态的状态下，经历了零次拷贝，所以才叫做零拷贝，
   2. 不是说不拷贝。