### 基础
发起方： LinkedIn
项目所属：Apache顶级项目 
开发语言：早期scala，后来java

### 是什么
分布式的流处理系统/消息中间件
基于发布-订阅模式.
流式数据处理
提供时间复杂度O(1)的消息持久化能力，即使对TB级以上数据也能保证常数时间复杂度的访问性能。
高吞吐率

### [流处理系统](https://blog.csdn.net/ransom0512/article/details/54691618)
- 处理无穷数据集的数据处理系统
- 流处理的六种方式： 
1. Event Sourcing，可以解释为事件溯源，该模式从事件源开始保存应用程序状态，保证每次更改都可以被保存为事件序列
它会完整的描述对象的整个生命周期中经历的所有事件。这方面典型的架构就是LMAX。
2. Reactive反应式编程，也称为响应式编程。顾名思义，就是根据用户的输入来做出响应。这种动作一般是实时的。
特点：
2.1消息驱动(响应式系统依靠异步消息在组件之间建立一个边界，确保组件之间的松耦合和隔离性)
2.2响应：响应性是系统高可用的基础。响应系统专注于提供快速一致的响应时间，建立可靠的上限，以便提供一致的服务质量
3. cep复杂事件处理。复杂事件处理描述的就是系统如何持续地处理这些事件，对系统对变化的持续反应。
主要依靠规则语言或者持续查询语言来完成事件的过滤、判断和处理。需要从大量的实践中过滤提取，按照既定的处理反应规则做处理
这类典型应用比如Esper，TIBCO，IBM Streams等。
4. 流处理架构，从大数据量领域发展起来的实时数据处理模型，其主要强调分布式，高性能，高可靠性
目前主要有Storm，Flink，Spark Streaming等
5. Actor模型包装了消息传输和封装机制，用户只需要面对消息和业务逻辑，因此天然就具有分布式、高并发、无状态的特性；对外提供简单编程接口。
6. 阶段事件驱动架构，其主要是将复杂的，事件驱动的应用分解为一系列通过队列连接的阶段，从而避免线程的并发模型带来高负载问题

- 流处理的目标
大部分流处理程序是用来实现核心的业务逻辑，而不是用于对业务进行分析。
这些应用更接近于一种异步的微服务，而不是批量分析任务的快速版本。

- 流处理的乱序问题
分布式的流处理系统，不可避免的会遇到数据的乱序问题，乱序问题一般的处理方式是使用时间排序窗口。
数据在进入节点之后，按照时间进行排序，然后等待一段时间，等待事件都已经到达之后再来进行下一步操作。
如果无法确定事件都已经到达，或者是由部分时间一直没有达到，那么就等到窗口超时为止，然后计算结果。


### 特性
- 水平扩展java、.net、php、ruby、python
- 高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒，每个topic可以分多个partition, consumer group 对partition进行consume操作。
- 可扩展性：kafka集群支持热扩展
- 持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失
- 容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）
- 高并发：支持数千个客户端同时读写
- 标准的二进制消息格式

### 使用场景
1.消息处理-即传统MQ的功能
2.度量监控,数据指标
3.log聚合，elk
4.流式处理


### 相关名词解释
- Topic：用来发布和订阅消息的主题。 
- Partition：topic的物理分组
- Segment：partition物理上由多个segment组成，每个Segment存着message信息 
- Broker：Kafka集群可以包含的一个或多个服务器，每个kafkaServer都是一个broker。
- Producer: 生产message发送到topic 
- Consumer: 订阅topic消费message, consumer作为一个线程来消费
- Group：一个Group包含多个consumer, 一条消息在一个group钟只能被消费一次。


* partition：为了使得kafka吞吐量线性提高，物理上把topic分成一个或者多个分区，  
  将消息*散列*到每个分区上，每一个分区是一个有序的队列。且每一个分区在物理上都对应着一个文件夹，该文件夹下存储这个分区所有消息和索引文件
  
* 消息是Kafka中最基本的数据单元，主要有key和value构成，key只是作为消息路由,存储到哪个partion上

### kafka在zookeeper中的目录结构
- /controller. 
     节点下为一个brokerId，作用：增加删除topic，更新分区副本数量，选举分区leader，集群broker增加和宕机后的调整；controller是由broker抢注节点选举的。
- /broker. 
    /brokers/ids/[brokerId],每个节点会保存对应broker的IP以及端口等信息
    /brokers/topics/topic. 每个topic都会在topics下建立独立的子节点，每个topic节点下都会包含分区以及broker的对应信息
- /consumer
    /consumers/[group_id]/ids/[consumer_id],该节点的内容是该消费者订阅的Topic信息
    /consumers/[group_id]/owners/[topic]/[broker_id-partition_id]，该节点的内容就是消费者的Consumer ID，此目录为消费者和分区的对应关心
- /zcs.zookeeper
    保存选举信息
- /config
    /isr_change_notification,   /log_dir_event_notification,   /latest_producer_id_block

### 生产者负载均衡
　　当Broker启动时，会注册该Broker的信息，以及可订阅的topic信息。  
   生产者通过注册在Broker以及Topic上的watcher动态的感知Broker以及Topic的分区情况，从而将Topic的分区动态的分配到broker上.
### 消费者负载均衡(老版本)
　　每个消费者会对/consumers/[group_id]/ids节点注册Watcher监听器，一旦消费者的数量增加或减少就会触发消费者的负载均衡。  
   消费者还会对/brokers/ids/[brokerid]节点进行监听，如果发现服务器的Broker服务器列表发生变化，也会进行消费者的负载均衡
### 消费者的offset
在kafka的消费者API分为两种
(1)High Level Api：  
    由zookeeper维护消费者的offset,/consumers/[group_id]/offsets/[topic]/[broker_id-part_id],该节点的值就是对应的offset 
(2) Low Level API,  
   自己的代码实现对offset的维护。Kafka版本[0.10.1.1]，已默认将消费的 offset 迁入到了 Kafka 一个名为 __consumer_offsets 的Topic中由于自己维护
 


## 生产者

### 生产者如何发送消息
基本流程：
（1）创建一个ProducerRecord，该对象需要包含消息的topic和value，可以选择性指定一个key（路由到不同分区）或者partition。 
（2）发送消息时，生产者会对key和value序列化成字节数组，然后发送到partitioner。 如果指定了partition，分配器就会返回该partition；否则分配器将会基于键值来选择一个分区并返回;DefaultPartitioner在key=null时会随机路由， key!=null时会hash路由 
（3）生产者将这条记录添加到相应的topic和partition的批量消息中，另一个线程负责发送这些批量消息到对应的Kafka broker。 
（4）broker接收到消息后，如果成功写入则返回一个RecordMetadata对象(含主题、分区及位移)，否则返回异常。 
（5）异常可能会进行重试。

注意：
- producer是线程安全的。所以多线程调用的时候，使用单个producer实例即可; 
- producer实际上是用多个线程并发地向不同分区所在的broker发起Socket连接同时给这些分区发送消息
- Producer解决消息如何路由到partition的，Producer中有个PartitionManager专门用于负责对每个Message分配partition
- send方法是异步的。每当调用他去增加一条记录附加到缓存时，他会立即返回。他可以允许producer把所有个别的记录集中在一起发送，以提高性能。

发送方式：
* 只发不管结果（fire-and-forget）：由于Kafka是高可用的，因此大部分情况下消息都会写入，但在异常情况下会丢消息。
* 同步发送（Synchronous send）：调用send()方法返回一个Future对象，我们可以使用它的get()方法来判断消息发送成功与否。
* 异步发送（Asynchronous send）：调用send()时提供一个回调方法，当接收到broker结果后回调此方法。

### 生产者幂等(0.11版本引入)
- 为了实现Producer的幂等性，Kafka引入了Producer ID（即PID）和Sequence Number。
- Broker端在缓存中保存了这seq number，对于接收的每条消息，如果其序号比Broker缓存中序号大于1则接受它，否则将其丢弃。
    只能保证单个Producer对于同一个<Topic, Partition>的Exactly Once语义。不能保证同一个Producer一个topic不同的partion幂等
- 配置
    enable.idempotence=ture,此时就会默认把acks=-1;

### 数据传输的事务定义通常有以下三种级别(对应生产者)：
（1）最多一次: 消息不会被重复发送，最多被传输一次，但也有可能一次不传输
（2）最少一次: 消息不会被漏发送，最少被传输一次，但也有可能被重复传输.
（3）精确的一次（Exactly once）: 不会漏传输也不会重复传输,每个消息都传输被一次而

### [事务](https://www.cnblogs.com/wangzhuxing/p/10125437.html) 
- Kafka的事务和数据库里用的ACID事务不是一个东西。主要是为了实现精确一次处理语义。事务场景有:
1. 只有producer生产消息：
     向同一个topic的多个分区发送多条消息。 要么全成功，要么全失败不对consumer可见；
     向多个topic的多个分区发送多条消息，这个操作也能放到一个是事务里，要么全成功，要么全失败；
2. 生产者和消费者共存：
     consume->transform->produce场景：先消费，处理完了再放到另一个topic里。
     这个操作可以放到一个事务里，中间任何一步失败都不能提交offset
3. consumer 实现了readCommitted和redUncommitted。(rc表示consumer只能读取producer事务成功的消息。ru表示consumer可以读取producer任何消息)

- producer提供了五个事务方法：
1. initTransactions(一个生产者只能执行一次初始化事务操作,目的是从事务协调器处获取pid)
2. beginTransaction(只是producer本地开启，只有开始发送第一条消息时，事务协调器才开始事务，往事务日志中写消息，并在事务日志中写<Transaction, Topic, Partition>关系)
3. sendOffsets(因为消费者提交偏移量出现问题，导致在重复消费消息时，生产者重复生产消息。需要将这个模式下消费者提交偏移量操作和生成者一系列生成消息的操作封装成一个原子操作,由生产者提交)
4. commitTransaction/abortTransaction
(2pc第一阶段，将Transaction Log内的该事务状态设置为PREPARE_COMMIT/PREPARE_ABORT
 2pc第二阶段，将Transaction Marker写入该事务涉及到的所有消息)


- 为了实现事务，kafka0.11版本引入概念
1.事务协调者(2pc)：类似于消费组负载均衡的协调者，每一个实现事务的生产端都被分配到一个事务协调者
2.事务Log(2pc)：引入一个内部持久化的Topic作为log。由事务协调者记录事务状态信息，
3.控制消息(2pc)：客户端产生的并写入到主题的特殊消息，但对于使用者来说不可见。是用来让broker告知消费者之前拉取的消息是否被原子性提交。
4.TransactionId：不同生产实例使用同一个TransactionId表示是同一个事务，可以跨Session的数据幂等发送。
  当具有相同Transaction ID的新的Producer实例被创建且工作时，旧的且拥有相同Transaction ID的Producer将不再工作，避免事务僵死。
5.epoch：生产者用于标识同一个事务Id，每次初始化事务时会递增，从而让服务端可以知道生产者请求是否旧的请求。

- 事务数据流
    -1. producer和事务coordinator的交互。执行事务时，Producer向事务协调员发出如下请求：
        1. initTransactions()向coordinator注册一个transactional.id。coordinator使用该transactional.id关闭所有待处理的事务，
             避免遇到僵尸实例。每个Producer会话只发生一次。
        2. 当Producer在事务中第一次将数据发送到分区时，首先向coordinator注册分区。
        3. 当调用commitTransaction或abortTransaction时，会向coordinator发送一个请求以开始两阶段提交协议。
    -2. Coordinator和事务日志交互
　　     1. Producer发送请求来更新Coordinator上事务的状态。事务Coordinator会在内存中保存每个事务的状态，并且把这个状态写到事务日志中
　　     2. 事务Coordinator是读写事务日志的唯一组件。如果一个给定的Borker故障了，一个新的Coordinator会被选为新的事务日志的Leader，
            这个事务日志分割了这个失效的代理，它从传入的分区中读取消息并在内存中重建状态。
    -3. Producer将数据写入目标Topic所在分区
　　     在Coordinator的事务中注册新的分区后，Producer将数据正常地发送到真实数据所在分区。
        这与producer.send流程完全相同，但有一些额外的验证，以确保Producer不被隔离。
    -4. Topic分区和Coordinator的交互
        1. 在Producer发起提交（或中止）之后，协调器开始两阶段提交协议。
        2. 在阶段1，Coordinator将其内部状态更新为“prepare_commit”并在事务日志中更新此状态。一旦完成了这个事务，无论发生什么事，都能保证事务完成。
        3. 在阶段2，在那里它将事务提交标记写入作为事务一部分的Topic分区。
        4. 这些事务标记不会暴露给应用程序，但是在read_committed模式下被Consumer使用来过滤掉被中止事务的消息，并且不返回属于开放事务的消息
        5. 一旦标记被写入，事务协调器将事务标记为“完成”，并且Producer可以开始下一个事务。
        
- 事务性能和优化
   - producer额外的写入在于：
      1. 对于每个事务，我们都有额外的RPC向Coordinator注册分区。
      2. 在完成事务时，必须将一个事务标记写入参与事务的每个分区。
      3. 最后，我们将状态更改写入事务日志。       
      总结：开销作为事务一部分，与写入的消息数量无关。所以拥有更高吞吐量的关键是每个事务包含更多的消息。
   - Consumer打开之后的性能
      1. 当以read_committed模式读取事务消息时，事务Consumer的吞吐量没有降低
      
- 事务配置
1、创建消费者代码，需要：
    1. auto.commit = false
    2. isolation.level = read committed / uncommitted
    3. 在代码里面也不能使用手动提交commitSync( )或者commitAsync( )
2、创建生成者，代码如下,需要:
    1. transactional.id = true/false
    2. enable.idempotence = true/false
    *. transaction.timeout.ms(可选)

[事务的理解](https://blog.csdn.net/muyimo/article/details/91439222)


#### 生产者常用配置
retries	                指定了重试的次数
client.id	用来识别消息是来自哪个客户端的
timeout.ms / request.timeout.ms / metadata.fetch.timeout.ms    	控制生产者等待broker的响应时间
max.block.ms	调用send方法或者获取元数据方法时的阻塞时间
max.request.size 限制生产者发送数据包的大小
receive.buffer.bytes / send.buffer.bytes	设置用来发送/接收数据的TCP连接的缓冲区

* batch.size 指定了producer维护了每个分区未被发送记录的缓存。配置这个参数足够大，可以缓存更多的记录，但同时也需要更多的内存。
* linger.ms	指定生产者在发送批量消息前等待的时间，batchSize和lingerms 只要有一个满足就会发送

* request.required.acks 数据可靠性级别：
  - 1（默认）：在ISR中的leader得到确认。如果leader宕机了，则会丢失数据。（便于记忆，1个leader，0个leader，-1个leader）
  - 0：无需等待来自broker的确认。传输效率最高，数据可靠性确最低。
  - -1：ISR中的所有follower都确认。但是这样也不能保证数据不丢失，比如当ISR中只有leader时

* buffer.memory 
  生产者缓冲发送的消息的内存大小(按topic分区来算）。如果记录发送的速度快于传输到服务器的速度，那么这个缓存可能会耗尽。
  当缓存的空间被耗尽，额外的发送请求将会被阻塞。阻塞时间的临界值由max.block.ms决定。之后将会抛出一个TimeoutException异常。
  
* max.in.flight.requests.per.connection  
    指定生产者可以发送多少消息到broker并且等待响应
    =1时可以保证发送到broker的顺序和调用send方法顺序一致，即便出现失败重试的情况也是如此
    =-1时使用操作系统自身的默认值。如果生产者与broker在不同的数据中心，建议提高receive.buffer.bytes, send.buffer.bytes，因为不同数据中心往往延迟比较大。




## 消费者

### 消费流程
* 创建一个KafkaConsumer。
* 订阅主题。
* 循环拉取消息。

注意：
  需要自己给消费者分配消费分区，而不是让消费者订阅（成为消费组）主题。

### 消息消费位置
*  最后的提交位移
*  指定位移
*  指定时间戳 

### 消费主题
* 可使用正则表达式订阅多个。
* 消费者对象不是线程安全的

* 一个partition能同时被多个group消费,每个group都是独立的，可以从头消费；
* 一个consumer线程可以同时消费多个partition

### 优雅退出消费
- 使用另一个线程调用consumer.wakeup()，调用此方法会使得poll()抛出WakeupException。(不用理会)
- 调用consumer.close()，此方法会提交位移，同时发送一个退出消费组的消息到Kafka的组协调者。

### 消费者的三种模式
- At most once 消息可能会丢，但绝不会重复传输
    1.设置enable.auto.commit=ture
    2.设置auto.commit.interval.ms为一个较小的时间间隔.
    3.client不要调用commitSync()，kafka在特定的时间间隔内自动提交。
    
- At least one 消息绝不会丢，但可能会重复传输
    1.设置enable.auto.commit=false
    2.client调用commitSync()，增加消息偏移;
    
- Exactly once 每条消息肯定会被传输一次且仅传输一次
    消费者配置：
      1.设置enable.auto.commit为false
      2.保存ConsumerRecord中的offset到数据库
      3.当partition分区发生变化的时候需要rebalance，consumer通过实现ConsumerRebalanceListener接口，捕捉这些事件，对偏移量进行处理。

### 消费者参数设置

- session.timeout.ms 默认3秒
- heartbeat.interval.ms 
  心跳是在consumer与coordinator之间进行的。心跳是确定consumer存活，加入或者退出group的有效手段。 
  
- max.poll.records
- max.partition.fetch.bytes 
  设置过大，那么消费者需要更长的时间来处理，可能会导致没有及时poll而会话过期
- max.poll.interval.ms 
  如果超过这个间隔没有发起pool请求，但heartbeat仍旧在发，就认为该consumer处于livelock状态。
  livelock时consumer退出consumer group。所以为了不使Consumer自己被退出，需要自己在程序中不停的调用poll方法了

- fetch.max.wait.ms
- fetch.min.bytes

- auto.offset.reset  默认latest
  当消费者第一次或重新读取分区时的行为： latest, earliest, none(没有offset就抛异常)
  当消费者宕机或者新消费者加入时，Kafka会进行重平衡，这会导致消费者负责之前并不属于它的分区。重平衡完成后，消费者会重新获取分区的位移，
  
- enable.auto.commit  自动提交（默认）
   消费者消费位移确认有自动提交与手动提交两种策略，如果需要减少重复消费或者数据丢失，你可以设置为手动提交。
   自动提交策略由消费者协调器（ConsumerCoordinator）每隔${auto.commit.interval.ms}毫秒执行一次偏移量的提交。默认5秒
   手动提交Kafka 提供了异步提交（commitAsync）及同步提交（commitSync）两种手动提交的方式。异步提交失败了不会重试     