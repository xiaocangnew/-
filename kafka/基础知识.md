### 基础
发起方： LinkedIn
项目所属：Apache顶级项目 
开发语言：早期scala，后来java

### 是什么
分布式的流处理系统/消息中间件
基于发布-订阅模式.
流式数据处理
提供时间复杂度O(1)的消息持久化能力，即使对TB级以上数据也能保证常数时间复杂度的访问性能。
高吞吐率

### 特性
- 水平扩展java、.net、php、ruby、python
- 高吞吐量、低延迟：kafka每秒可以处理几十万条消息，它的延迟最低只有几毫秒，每个topic可以分多个partition, consumer group 对partition进行consume操作。
- 可扩展性：kafka集群支持热扩展
- 持久性、可靠性：消息被持久化到本地磁盘，并且支持数据备份防止数据丢失
- 容错性：允许集群中节点失败（若副本数量为n,则允许n-1个节点失败）
- 高并发：支持数千个客户端同时读写
- 标准的二进制消息格式

### 使用场景
1.消息处理-即传统MQ的功能
2.度量监控,数据指标
3.log聚合，elk
4.流式处理


### 相关名词解释
- Topic：用来发布和订阅消息的主题。 
- Partition：topic的物理分组
- Segment：partition物理上由多个segment组成，每个Segment存着message信息 
- Broker：Kafka集群可以包含的一个或多个服务器。
- Producer: 生产message发送到topic 
- Consumer: 订阅topic消费message, consumer作为一个线程来消费
- Group：一个Group包含多个consumer, 一条消息在一个group钟只能被消费一次。


* partition：为了使得kafka吞吐量线性提高，物理上把topic分成一个或者多个分区，  
  将消息*散列*到每个分区上，每一个分区是一个有序的队列。且每一个分区在物理上都对应着一个文件夹，该文件夹下存储这个分区所有消息和索引文件
  
* 消息是Kafka中最基本的数据单元，主要有key和value构成，key只是作为消息路由,存储到哪个partion上

### kafka在zookeeper中的目录结构
- /controller. 
     节点下为一个brokerId，作用：增加删除topic，更新分区副本数量，选举分区leader，集群broker增加和宕机后的调整；controller是由broker抢注节点选举的。
- /broker. 
    /brokers/ids/[brokerId],每个节点会保存对应broker的IP以及端口等信息
    /brokers/topics/topic. 每个topic都会在topics下建立独立的子节点，每个topic节点下都会包含分区以及broker的对应信息
- /consumer
    /consumers/[group_id]/ids/[consumer_id],该节点的内容是该消费者订阅的Topic信息
    /consumers/[group_id]/owners/[topic]/[broker_id-partition_id]，该节点的内容就是消费者的Consumer ID，此目录为消费者和分区的对应关心
- /zcs.zookeeper
    保存选举信息
- /config
    /isr_change_notification,   /log_dir_event_notification,   /latest_producer_id_block

### 生产者负载均衡
　　当Broker启动时，会注册该Broker的信息，以及可订阅的topic信息。  
   生产者通过注册在Broker以及Topic上的watcher动态的感知Broker以及Topic的分区情况，从而将Topic的分区动态的分配到broker上.
### 消费者负载均衡
　　每个消费者会对/consumers/[group_id]/ids节点注册Watcher监听器，一旦消费者的数量增加或减少就会触发消费者的负载均衡。  
   消费者还会对/brokers/ids/[brokerid]节点进行监听，如果发现服务器的Broker服务器列表发生变化，也会进行消费者的负载均衡
### 消费者的offset
在kafka的消费者API分为两种
(1)High Level Api：  
    由zookeeper维护消费者的offset,/consumers/[group_id]/offsets/[topic]/[broker_id-part_id],该节点的值就是对应的offset 
(2) Low Level API,  
   自己的代码实现对offset的维护。Kafka版本[0.10.1.1]，已默认将消费的 offset 迁入到了 Kafka 一个名为 __consumer_offsets 的Topic中由于自己维护
 


## 生产者

### 生产者如何发送消息
基本流程：
（1）创建一个ProducerRecord，该对象需要包含消息的topic和value，可以选择性指定一个key（路由到不同分区）或者partition。 
（2）发送消息时，生产者会对key和value序列化成字节数组，然后发送到partitioner。 如果指定了partition，分配器就会返回该partition；否则分配器将会基于键值来选择一个分区并返回;DefaultPartitioner在key=null时会随机路由， key!=null时会hash路由 
（3）生产者将这条记录添加到相应的topic和partition的批量消息中，另一个线程负责发送这些批量消息到对应的Kafka broker。 
（4）broker接收到消息后，如果成功写入则返回一个RecordMetadata对象(含主题、分区及位移)，否则返回异常。 
（5）异常可能会进行重试。

注意：
- producer是线程安全的。所以多线程调用的时候，使用单个producer实例即可; 
- producer实际上是用多个线程并发地向不同分区所在的broker发起Socket连接同时给这些分区发送消息
- Producer解决消息如何路由到partition的，Producer中有个PartitionManager专门用于负责对每个Message分配partition
- send方法是异步的。每当调用他去增加一条记录附加到缓存时，他会立即返回。他可以允许producer把所有个别的记录集中在一起发送，以提高性能。

发送方式：
* 只发不管结果（fire-and-forget）：由于Kafka是高可用的，因此大部分情况下消息都会写入，但在异常情况下会丢消息。
* 同步发送（Synchronous send）：调用send()方法返回一个Future对象，我们可以使用它的get()方法来判断消息发送成功与否。
* 异步发送（Asynchronous send）：调用send()时提供一个回调方法，当接收到broker结果后回调此方法。

### 生产者幂等(0.11版本引入)
- 为了实现Producer的幂等性，Kafka引入了Producer ID（即PID）和Sequence Number。
- Broker端在缓存中保存了这seq number，对于接收的每条消息，如果其序号比Broker缓存中序号大于1则接受它，否则将其丢弃。
    只能保证单个Producer对于同一个<Topic, Partition>的Exactly Once语义。不能保证同一个Producer一个topic不同的partion幂等
- 配置
    enable.idempotence=ture,此时就会默认把acks设置为all

### 数据传输的事务定义通常有以下三种级别(对应生产者)：
（1）最多一次: 消息不会被重复发送，最多被传输一次，但也有可能一次不传输
（2）最少一次: 消息不会被漏发送，最少被传输一次，但也有可能被重复传输.
（3）精确的一次（Exactly once）: 不会漏传输也不会重复传输,每个消息都传输被一次而

### [事务](https://www.cnblogs.com/wangzhuxing/p/10125437.html) Kafka的事务和数据库里用的ACID事务不是一个东西。
- Kafka的事务主要用来处理consume-process-produce场景的原子性问题：
一个数据处理服务从Kafka的若干源topic取数据，处理后，再发送到另外一些目标topic里。在这个过程中，Kafka事务保证：
1.要么数据被处理了，目标topic的结果被正确写入，源topic的数据被消费掉；
2.要么这个数据还能从源topic里读取到，就像没被处理过一样，不会出现源topic还没consume，目标topic已经produce出去的情况。

#### 生产者常用配置
retries	                指定了重试的次数
client.id	用来识别消息是来自哪个客户端的
timeout.ms / request.timeout.ms / metadata.fetch.timeout.ms    	控制生产者等待broker的响应时间
max.block.ms	调用send方法或者获取元数据方法时的阻塞时间
max.request.size 限制生产者发送数据包的大小
receive.buffer.bytes / send.buffer.bytes	设置用来发送/接收数据的TCP连接的缓冲区

* batch.size 指定了producer维护了每个分区未被发送记录的缓存。配置这个参数足够大，可以缓存更多的记录，但同时也需要更多的内存。
* linger.ms	指定生产者在发送批量消息前等待的时间，batchSize和lingerms 只要有一个满足就会发送

* request.required.acks 数据可靠性级别：
  - 1（默认）：在ISR中的leader得到确认。如果leader宕机了，则会丢失数据。（便于记忆，1个leader，0个leader，-1个leader）
  - 0：无需等待来自broker的确认。传输效率最高，数据可靠性确最低。
  - -1：ISR中的所有follower都确认。但是这样也不能保证数据不丢失，比如当ISR中只有leader时

* buffer.memory 
  生产者缓冲发送的消息的内存大小(按topic分区来算）。如果记录发送的速度快于传输到服务器的速度，那么这个缓存可能会耗尽。
  当缓存的空间被耗尽，额外的发送请求将会被阻塞。阻塞时间的临界值由max.block.ms决定。之后将会抛出一个TimeoutException异常。
  
* max.in.flight.requests.per.connection  
    指定生产者可以发送多少消息到broker并且等待响应
    =1时可以保证发送到broker的顺序和调用send方法顺序一致，即便出现失败重试的情况也是如此
    =-1时使用操作系统自身的默认值。如果生产者与broker在不同的数据中心，建议提高receive.buffer.bytes, send.buffer.bytes，因为不同数据中心往往延迟比较大。




## 消费者

### 消费流程
* 创建一个KafkaConsumer。
* 订阅主题。
* 循环拉取消息。

注意：
  需要自己给消费者分配消费分区，而不是让消费者订阅（成为消费组）主题。

### 消息消费位置
*  最后的提交位移
*  指定位移
*  指定时间戳 

### 消费主题
* 可使用正则表达式订阅多个。
* 消费者对象不是线程安全的

* 一个partition能同时被多个group消费,每个group都是独立的，可以从头消费；
* 一个consumer线程可以同时消费多个partition

### 优雅退出消费
- 使用另一个线程调用consumer.wakeup()，调用此方法会使得poll()抛出WakeupException。(不用理会)
- 调用consumer.close()，此方法会提交位移，同时发送一个退出消费组的消息到Kafka的组协调者。

### 消费者的三种模式
- At most once 消息可能会丢，但绝不会重复传输
    1.设置enable.auto.commit=ture
    2.设置auto.commit.interval.ms为一个较小的时间间隔.
    3.client不要调用commitSync()，kafka在特定的时间间隔内自动提交。
    
- At least one 消息绝不会丢，但可能会重复传输
    1.设置enable.auto.commit=false
    2.client调用commitSync()，增加消息偏移;
    
- Exactly once 每条消息肯定会被传输一次且仅传输一次
    消费者配置：
      1.设置enable.auto.commit为false
      2.保存ConsumerRecord中的offset到数据库
      3.当partition分区发生变化的时候需要rebalance，consumer通过实现ConsumerRebalanceListener接口，捕捉这些事件，对偏移量进行处理。

### 消费者参数设置

- session.timeout.ms 默认3秒
- heartbeat.interval.ms 
  心跳是在consumer与coordinator之间进行的。心跳是确定consumer存活，加入或者退出group的有效手段。 
  
- max.poll.records
- max.partition.fetch.bytes 
  设置过大，那么消费者需要更长的时间来处理，可能会导致没有及时poll而会话过期
- max.poll.interval.ms 
  如果超过这个间隔没有发起pool请求，但heartbeat仍旧在发，就认为该consumer处于livelock状态。
  livelock时consumer退出consumer group。所以为了不使Consumer自己被退出，需要自己在程序中不停的调用poll方法了

- fetch.max.wait.ms
- fetch.min.bytes

- auto.offset.reset  默认latest
  当消费者第一次或重新读取分区时的行为： latest, earliest, none(没有offset就抛异常)
  当消费者宕机或者新消费者加入时，Kafka会进行重平衡，这会导致消费者负责之前并不属于它的分区。重平衡完成后，消费者会重新获取分区的位移，
  
- enable.auto.commit  自动提交（默认）
   消费者消费位移确认有自动提交与手动提交两种策略，如果需要减少重复消费或者数据丢失，你可以设置为手动提交。
   自动提交策略由消费者协调器（ConsumerCoordinator）每隔${auto.commit.interval.ms}毫秒执行一次偏移量的提交。默认5秒
   手动提交Kafka 提供了异步提交（commitAsync）及同步提交（commitSync）两种手动提交的方式。异步提交失败了不会重试
   
### 协调器
- 0.10版本引入了协调器概念，包括两个：
- groupCoordinator
   用于管理消费者组和该消费者组下每个消费者的消费偏移量。每个kafkaServer启动时都会启动一个协调器；
- consumerCoordinator
   负责同一个消费者组下各消费者与 GroupCoordinator进行通信。每个consumer启动时都会启动一个协调器；
   
- groupCoordinator与consumerCoordinator通信过程
   - 1. 心跳
   - 2. 分区再均衡 (此时不提供服务)
          当发生以下情况，会进行再均衡：1.新加入consumer；2.新离开consumer； 3.topic新增加分区时；
   - 3. consumerLeader分配分区策略(此时groupCoordinator只存储和中间转发人)
         1. 当消费者要加入群组时，它会向群组协调器发送一个 JoinGroup 请求。第一个加入群组的消费者将成为leader消费者。
             leader消费者从组协调器那里获得群组的成员列表，并负责给每一个消费者分配分区。 
         2. 每个消费者的消费者协调器在向组协调器请求加入组时，都会把自己支持的分区分配策略报告给组协调器(轮询或者是按跨度分配或者其他)，
             组协调器选出该消费组下所有消费者都支持的的分区分配策略发送给leader消费者，leader消费者根据这个分区分配策略进行分配。
         3. leader消费者把分配情况列表发送给组协调器，组协调器把这些信息发送给所有消费者。
            每个消费者只能看到自己的分配信息，只有leader消费者知道群组里所有消费者的分配信息。这个过程会在每次再均衡时重复发生。
         
-  consumerLeader支持的分区分配策略
     1.轮询： 把消费者组消费的所有topic 拿出来，统一排序，轮询给所有consumer。 缺点：在多topic下，导一个topic被好几个consumer消费；
     2.range策略(默认)： 把消费同一个topic的所有consumer排序，尽量均分；如果不平均的话，排在前面的多，0-2parition归consumer1，3-4partition归consumer2
     
     
     
### 高性能的日志存储 kafka采用了稀疏索引的方式 
每个Partition其实都会对应一个日志目录，在目录下面会对应多个日志分段(LogSegment = “.index”索引文件 + “.log”日志文件)。
先通过index文件，利用二分查找法，找到相应的稀疏索引，然后跟进index上的偏移量，找到log文件的位置，然后在log顺序遍历上面找到相应的文件；

- 优点
   index file采取稀疏索引存储方式，它减少索引文件大小，通过mmap可以直接内存操作，稀疏索引为数据文件的每个对应message设置一个元数据指针,
   它比稠密索引节省了更多的存储空间，但查找起来需要消耗更多的时间。
- 稀疏索引
   并不是所有条目都有索引项，只有一些有。查找时先找到最近的，再遍历。