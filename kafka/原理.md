### 基础架构
一个典型的Kafka体系架构包括:
* 若干Producer,
* 若干broker(Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高)
* 若干Consumer (Group)
* 以及一个Zookeeper集群。

### zookeeper在kafka中的作用
* 管理集群配置，实现动态的集群扩展，不需要更改客户端（producer和consumer）的配置，broker会在zookeeper注册并保持相关的元数据（topic，partition信息等）更新,  
   以及监测partitionleader存活性.
* 选举leader
* 客户端会在zookeeper上注册相关的watcher。一旦zookeeper发生变化，客户端能及时感知并作出相应调整。这样就保证了添加或去除broker时，各broker间仍能自动实现负载均衡。  
   这里的客户端指的是Kafka的消息生产端(Producer)和消息消费端(Consumer)
* Consumer端使用zookeeper用来注册consumer信息,其中包括consumer消费的partition列表等,同时也用来发现broker列表,并和partitionleader建立socket连接,并获取消息.
* Zookeeper和Producer没有建立关系，Producer是瞬态的，可以发送后关闭，无需直接等待,
* Zookeeper和Brokers、Consumers建立关系以实现负载均衡，即同一个ConsumerGroup中的Consumers可以实现负载均衡

### 消费方式
* Producer使用push(推)模式将消息发布到broker
* Consumer使用pull(拉)模式从broker订阅并消费消息。

### topic
[topic 创建过程](https://www.cnblogs.com/huxi2b/p/5923252.html)


### 重平衡  ConsumerRebalanceListener
- 时机
   * 新的消费者加入消费组，它会消费一个或多个分区，而这些分区之前是由其他消费者负责的；  
   * 消费者离开消费组（比如重启、宕机等）时，它所消费的分区会分配给其他分区。
- 在重平衡期间，所有消费者都不能消费消息，因此会造成整个消费组短暂的不可用。
- 将分区进行重平衡也会导致原来的消费者状态过期，从而导致消费者需要重新更新状态，

- 消费者存活
   消费者通过定期发送心跳（hearbeat）到一个作为组协调者（group coordinator）的broker来保持在消费组内存活。
   从消费者宕机到会话过期是有一定时间的，这段时间内该消费者的分区都不能进行消息消费；

- 通常情况下，我们可以进行优雅关闭，这样消费者会发送离开的消息到组协调者，这样组协调者可以立即进行重平衡而不需要等待会话过期。

## 消息存储方式

### 几个概念
- partition
  说明:分区，对应目录中的文件夹： topic-0 、 topic-1...
  
- LogSegment
  说明: 每个分区被分为多个片段，是一个逻辑概念, 对应三个文件  .log + .index + .timeindex
  文件说明：
  - .index文件
    使用稀疏索引的方式建立(每隔一定的字节数建立了一条索引)，格式内容：offset: 22372444 position: 16365
    通过“index.interval.bytes”设置索引的跨度
    具体的做法是，根据指定的偏移量，使用二分法查询定位出该偏移量对应的消息所在的分段索引文件和日志数据文件。
    然后通过二分查找法，继续查找出小于等于指定偏移量的最大偏移量，同时也得出了对应的position（实际物理位置），
    根据该物理位置在分段的日志数据文件中顺序扫描查找偏移量与指定偏移量相等的消息。
  - .timeindex文件
     
  
-message
  说明：固定消息头+可变消息体
  消息体中几个主要字段：
   - offset 消息偏移量
   - message size 消息总长度
   - CRC32 编码校验和
   - key 消息key的时实际数据
   - key length 消息key长度
   - valuesize 消息的实际数据长度
   - playload 消息的实际数据
    
- 顺序写入磁盘
  通过追加写的方式来尽可能的将随机I/O转换为顺序I/O，以此来降低寻址时间和旋转延时，从而最大限度的提高IOPS。
  
-去服务器看partition下面的文件结构
 文件命名规则
 其中以索引文件中元数据3,497为例，依次在数据文件中表示第3个message、以及该消息的物理偏移地址。
 第一步查找segment file，第二步通过segment file查找message
 
 查看 消费消息后的索引情况 ：ls /brokers/topics/__consumer_offsets/partitions 


### 旧日志删除策略
- 基于时间
   Log.retention.hours=168
   默认保留7天
- 基于大小
   Log.retention.bytes=1073741824
   默认1G
   读取特定消息的时间复杂度为O(1)，删除数据不会对效率产生影响

 
### 高可用

#### 名词解释
- Controller：集群管理控制器（本身也是个broker）
- ISR（In Sync Replica）：副本同步组，表示基本跟上leader的replica
- LEO（Log End Offset）：每个partition的log最后一条Message的位置。
- HW（High Watermark）：高水位，取ISR中最小的LEO作为HW，消费者最多只能消费到HW所在的位置。

* controller
  - 功能
    增加删除topic，更新分区副本数量，选举partition分区leader，集群broker增加和宕机后的调整，当然还有自身的选举controller leader功能
  - controller失败 
   幸存的所有broker都会尝试在Zookeeper中创建/controller->{this broker id}，如果创建成功（只可能有一个创建成功），则该broker会成为controller，若创建不成功，则该broker会等待新controller的命令。
  - 作用
   降低了zookeeper的负载。要是所有的broker都监视/brokers/ids那么一旦集群成员发生变化,那么zk得挨个提醒broker回调.但是现在只用提醒leader就行了,
   唯一让zk很辛苦的情况就是leader崩溃.不过这种情况比较少


#### 副本partition参数设置
- replica.lag.max.messages 落后的消息个数(0.10.x版本移除，因为瞬时大量消息会导致ISR中没有问题的replica也被移除了)
- replica.lag.time.max.ms 多长时间没有发送FetchQuest请求拉去leader数据

#### 数据可靠性
- 数据可靠性：每个Partition会有一个leader和零或多个follower，每个leader可能在不同的broker上
- 所有读写操作都是由leader处理
- follower像普通的consumer那样从leader那里拉取消息并保存在自己的日志文件中，
- Kafka中每个Broker启动时都会创建一个副本管理服务(ReplicaManager)，该服务负责维护ReplicaFetcherThread与其他Broker链路连接关系，  
  有多少Broker就会创建相同数量的ReplicaFetcherThread线程同步对应partition数据，follower每次读取消息都会更新HW状态。

#### partition的leader选举
1. controller获取set_p（set_p包含了宕机的所有Broker上的所有Partition）
2.对set_p中的每一个Partition ，从/brokers/topics/[topic]/partitions/[partition]/state读取该Partition当前的ISR， 
   - 当前ISR中有至少一个Replica还幸存，则选择其中一个作为新Leader，
   - 否则选择该Partition中任意一个幸存的Replica作为新的Leader以及ISR（该场景下可能会有潜在的数据丢失）。
   - 如果该Partition的所有Replica都宕机了，则将新的Leader设置为-1。将新的Leader，ISR和新的leader_epoch及controller_epoch写入/brokers/topics/[topic]/partitions/[partition]/state。 
3.通过RPC向set_p相关的Broker发送LeaderAndISRRequest命令。Controller可以在一个RPC操作中发送多个命令从而提高效率。

### Replication
- 同步复制
   request.required.acks
   发送消息要求ACK，全部ISR都接收到之后消息才会被commit
   不丢消息、吞吐率受影响
- 异步复制
   不要求ACK
   ISR定期向leader批量请求数据，进行同步
   当所有ISR都落后时，如果leader挂掉，则丢数据
   平衡了性能-数据不丢失
