###为什么要用消息系统
解耦 – 基于数据的接口层
可扩展性 – 易于水平扩展
异步 – 默认异步处理
削峰 – 不会被突发的超负荷压垮

### Kafka 判断一个节点是否还活着有那两个条件？
1. 节点必须可以维护和 ZooKeeper 的连接，Zookeeper 通过心跳机制检查每个节点的连接
2. 如果节点是个follower,他必须能及时的同步leader的写操作，延时不能太久


### kafka为什么这么快
- 顺序写磁盘
- 大量使用内存页
   - 利用(Memory-Mapped-Files,mmap技术)
       直接利用操作系统的Page来实现磁盘文件到物理内存的直接映射
       写到mmap中的数据并没有被真正的写到硬盘，操作系统会在程序主动调用flush的时候才把数据真正的写到硬盘。
   - producer.type 参数控制是不是主动flush
       同步(sync): Kafka写入到mmap之后就立即flush然后再返回Producer
       异步(async,默认):写入mmap之后立即返回Producer不调用flush
- 零拷贝技术

#### 与rabbitmq对比  RabbitMQ是一个消息代理  Kafka是一个分布式流式系统
- 在消息顺序性上的差异
   - rabbitmq 在多消费者时无法保证顺行性，单消费者保证顺序；
   - kafka 由消费者组保证每个topic只有一个消费者，是顺序的；
- 消息路由上的差异
   - rabbitmq支持复杂路由
   - kafka只支持简单的topic路由
- 消息留存
   - rabbitmq作为一个消息代理，消息处理完毕就删除不保留，同时queue里消息过多影响性能
   - kafka 可以设置保存时间，重复消费，消息数量的多少也不影响性能；
- 容错处理
   - 故障包括瞬时故障(io问题，cpu负载瞬时过高等)， 永久故障(程序bug，无效消息格式等)
   - rabbitmq 提供了交付重试和死信队列，同时一个消息出问题不影响其他消费者；
   - kafka 需要我们自己定制重试机制，同时当topic一个消息出问题时，顺序在后面的消息无法消费；
- 性能
   - kafka比rabbitmq更好，
- 伸缩性
   - rabbitmq 只需要简单的增删消费者就可以了
   - kafka 在增加流量时，由于一个topic只能被消费组中的一个消费者消费，只能拓展topic的分区数量，增加更多消费者
           在减少流量后，topic的分区不能向下减少(只能增加不能减少)

- 优先选择 RabbitMQ 的条件：
     高级灵活的路由规则消息时序控制（控制消息过期或者消息延迟）
     高级的容错处理能力，在消费者更有可能处理消息不成功的情景中（瞬时或者持久）更简单的消费者实现
- 优先选择 Kafka 的条件：
     严格的消息顺序延长消息留存时间，包括过去消息重放的可能
     高伸缩能力
  
### 消息的乱序性（在同一个partition内有序）
producer.send(record1);
producer.send(record2);
如果此时由于某些原因(比如瞬时的网络抖动)导致record1没有成功发送，同时Kafka又配置了重试机制和max.in.flight.requests.per.connection大于1(默认值是5，本来就是大于1的)， 
那么重试record1成功后，record1在分区中就在record2之后，从而造成消息的乱序。很多某些要求强顺序保证的场景是不允许出现这种情况的，设置=1即可避免


### 如何处理kafka所有Replica都不工作
- 在ISR中至少有一个follower时，Kafka可以确保已经commit的数据不丢失，
如果某个Partition的所有Replica都宕机了，就无法保证数据不丢失了。这种情况下有两种可行的方案：
 - 1.等待ISR中的任一个Replica“活”过来，并且选它作为Leader(如果ISR中的所有Replica都无法“活”过来了，或者数据都丢失了，这个Partition将永远不可用)
 - 2.（不一定是ISR中的）第一个“活”过来的Replica作为Leader

- unclean.leader.election.enable 参数决定使用哪种方案，默认是true，采用第二种方案

### kafka客户端使用缓冲池的机制
在客户端发送消息给kafka服务器的时候，一定是有一个内存缓冲机制的，消息会先写入一个内存缓冲中，然后直到多条消息组成了一个Batch，才会一次网络通信把Batch发送过去。避免了一条消息一次网络请求。从而提升了吞吐量，
每个Batch底层都对应一块内存空间，使用完毕内存空间不交给JVM去垃圾回收，而是把这块内存空间给放入一个缓冲池里。

### Kafka 分区的目的？
 分区对于Kafka集群的好处是：实现负载均衡。分区对于消费者来说，可以提高并发度，提高效率
 
### Kafka 是如何保证数据可靠性和一致性

- 保证数据可靠性，不丢失消息
1. broker级别：关闭不完全的Leader选举，即 unclean.leader.election.enable=false；
      (即不允许非ISR中的副本被选举为leader，以避免数据丢失)
2. topic级别：设置 replication.factor>=3，并且 min.insync.replicas>=2；
3. producer级别：
       acks=all（或者 request.required.acks=-1），
       发送模式为同步 producer.type=sync (异步时发送后先保存在缓冲区中，如果宕机则丢失全部消息)
       关闭自动提交：enable.auto.commit=false
       提交缓冲区满后一直阻塞不抛异常：block.on.buffer.full = true  尽管该参数在0.9.0.0已经被标记为“deprecated”，但鉴于它的含义非常直观，所以这里还是显式设置它为true，使得producer将一直等待缓冲区直至其变为可用。否则如果producer生产速度过快耗尽了缓冲区，producer将抛出异常。缓冲区满了就阻塞在那，不要抛异常，也不要丢失数据       
       
- 保证数据的一致性
 数据可靠性是由ISR中HW来控制的。
 
### Kafka 消费者是否可以消费指定分区消息？
- kafka消费者有两种模式, 订阅模式和分配模式
    订阅模式subscribe： 使用Kafka Group管理，自动进行rebalance操作
    分配模式assign： 用户自己进行相关的处理。consumer.assign(partitionList);   consumer.seek(partition, offset); 指定分区和位移
    一个consumer只能处于两种模式之一。

### Kafka消息是采用Pull模式，还是Push模式
Kafka遵循了一种大部分消息系统共同的传统的设计：producer将消息推送到broker，consumer从broker拉取消息。
Kafka有个参数可以让consumer阻塞知道新消息到达(防止brokers没消息时consuemr空轮询)

### kafka中的选举机制
见distribute-theory -> kafka选举