Kafka 选主怎么做的？
kafka 与rabbitmq区别
kafka 分区怎么同步的
kafka 怎么保证不丢消息的




###为什么要用消息系统
解耦 – 基于数据的接口层
可扩展性 – 易于水平扩展
异步 – 默认异步处理
削峰 – 不会被突发的超负荷压垮
可恢复 – 消费者挂掉 消息还在 消费者恢复后可以继续消费
顺序性 – FIFO 保证消息处理的顺序


### Kafka 判断一个节点是否还活着有那两个条件？
1. 节点必须可以维护和 ZooKeeper 的连接，Zookeeper 通过心跳机制检查每个节点的连接
2. 如果节点是个follower,他必须能及时的同步leader的写操作，延时不能太久


### kafka为什么这么快
- 顺序写磁盘
- 大量使用内存页
   - 利用(Memory-Mapped-Files,mmap技术)
       直接利用操作系统的Page来实现文件到物理内存的直接映射
       写到mmap中的数据并没有被真正的写到硬盘，操作系统会在程序主动调用flush的时候才把数据真正的写到硬盘。
   - producer.type 参数控制是不是主动flush
       同步(sync): Kafka写入到mmap之后就立即flush然后再返回Producer
       异步(async,默认):写入mmap之后立即返回Producer不调用flush
- 零拷贝技术

#### 与rabbitmq对比  RabbitMQ是一个消息代理  Kafka是一个分布式流式系统
- 在消息顺序性上的差异
   - rabbitmq 在多消费者时无法保证顺行性，单消费者保证顺序；
   - kafka 由消费者组保证每个topic只有一个消费者，是顺序的；
- 消息路由上的差异
   - rabbitmq支持复杂路由
   - kafka只支持简单的topic路由
- 消息留存
   - rabbitmq作为一个消息代理，消息处理完毕就删除不保留，同时queue里消息过多影响性能
   - kafka 可以设置保存时间，重复消费，消息数量的多少也不影响性能；
- 容错处理
   - 故障包括瞬时故障(io问题，cpu负载瞬时过高等)， 永久故障(程序bug，无效消息格式等)
   - rabbitmq 提供了交付重试和死信队列，同时一个消息出问题不影响其他消费者；
   - kafka 需要我们自己定制重试机制，同时当topic一个消息出问题时，顺序在后面的消息无法消费；
- 性能
   - kafka比rabbitmq更好，
- 伸缩性
   - rabbitmq 只需要简单的增删消费者就可以了
   - kafka 在增加流量时，由于一个topic只能被消费组中的一个消费者消费，只能拓展topic的分区数量，增加更多消费者
           在减少流量后，topic的分区不能向下减少(只能增加不能减少)

- 优先选择 RabbitMQ 的条件：
     高级灵活的路由规则消息时序控制（控制消息过期或者消息延迟）
     高级的容错处理能力，在消费者更有可能处理消息不成功的情景中（瞬时或者持久）更简单的消费者实现
- 优先选择 Kafka 的条件：
     严格的消息顺序延长消息留存时间，包括过去消息重放的可能
     高伸缩能力
  

#### 生产的信息不丢失
1）使用同步模式的时候，在request.required.acks=1（只保证写入leader成功），leader partition挂了，数据就会丢失。
2）使用异步模式的时候，当缓冲区满了，如果配置为0（还没有收到确认的情况下，缓冲池一满，就清空缓冲池里的消息），数据就会被立即丢弃掉；（在配置文件中设置成不限制阻塞超时的时间，也就说让生产端一直阻塞，这样也能保证数据不会丢失）
3）consumer端丢失消息的情形比较简单：如果在消息处理完成前就提交了offset，那么就有可能造成数据的丢失现给出两点建议：enable.auto.commit=false  关闭自动提交位移；在消息被完整处理之后再手动提交位移

### 消息的乱序性（在同一个partition内有序）
producer.send(record1);
producer.send(record2);
  如果此时由于某些原因(比如瞬时的网络抖动)导致record1没有成功发送，同时Kafka又配置了重试机制和max.in.flight.requests.per.connection大于1(默认值是5，本来就是大于1的)， 
  那么重试record1成功后，record1在分区中就在record2之后，从而造成消息的乱序。很多某些要求强顺序保证的场景是不允许出现这种情况的


### 如何处理kafka所有Replica都不工作

在ISR中至少有一个follower时，Kafka可以确保已经commit的数据不丢失，但如果某个Partition的所有Replica都宕机了，就无法保证数据不丢失了。这种情况下有两种可行的方案：
1.等待ISR中的任一个Replica“活”过来，并且选它作为Leader(如果ISR中的所有Replica都无法“活”过来了，或者数据都丢失了，这个Partition将永远不可用)
2.选择第一个“活”过来的Replica（不一定是ISR中的）作为Leader

- unclean.leader.election.enable 参数决定使用哪种方案，默认是true，采用第二种方案

### kafka客户端使用缓冲池的机制
在客户端发送消息给kafka服务器的时候，一定是有一个内存缓冲机制的，消息会先写入一个内存缓冲中，然后直到多条消息组成了一个Batch，才会一次网络通信把Batch发送过去。避免了一条消息一次网络请求。从而提升了吞吐量，
每个Batch底层都对应一块内存空间，使用完毕内存空间不要交给JVM去垃圾回收，而是把这块内存空间给放入一个缓冲池里。